{"metadata":{"kernelspec":{"display_name":"Python 3","language":"python","name":"python3"},"language_info":{"name":"python","version":"3.10.13","mimetype":"text/x-python","codemirror_mode":{"name":"ipython","version":3},"pygments_lexer":"ipython3","nbconvert_exporter":"python","file_extension":".py"},"kaggle":{"accelerator":"nvidiaTeslaT4","dataSources":[{"sourceId":7137971,"sourceType":"datasetVersion","datasetId":4119222},{"sourceId":7674506,"sourceType":"datasetVersion","datasetId":4476677},{"sourceId":7690418,"sourceType":"datasetVersion","datasetId":4487952},{"sourceId":7690803,"sourceType":"datasetVersion","datasetId":4488232}],"dockerImageVersionId":30648,"isInternetEnabled":true,"language":"python","sourceType":"notebook","isGpuEnabled":true}},"nbformat_minor":4,"nbformat":4,"cells":[{"cell_type":"code","source":"!python --version","metadata":{"execution":{"iopub.status.busy":"2024-03-19T04:17:00.566351Z","iopub.execute_input":"2024-03-19T04:17:00.566714Z","iopub.status.idle":"2024-03-19T04:17:01.543110Z","shell.execute_reply.started":"2024-03-19T04:17:00.566687Z","shell.execute_reply":"2024-03-19T04:17:01.542077Z"},"trusted":true},"execution_count":null,"outputs":[]},{"cell_type":"code","source":"%pip install keras==2.15.0","metadata":{"execution":{"iopub.status.busy":"2024-03-19T04:17:01.548031Z","iopub.execute_input":"2024-03-19T04:17:01.548321Z","iopub.status.idle":"2024-03-19T04:17:13.989184Z","shell.execute_reply.started":"2024-03-19T04:17:01.548281Z","shell.execute_reply":"2024-03-19T04:17:13.988010Z"},"trusted":true},"execution_count":null,"outputs":[]},{"cell_type":"code","source":"!pip show keras","metadata":{"execution":{"iopub.status.busy":"2024-03-19T04:17:13.990876Z","iopub.execute_input":"2024-03-19T04:17:13.991191Z","iopub.status.idle":"2024-03-19T04:17:25.816382Z","shell.execute_reply.started":"2024-03-19T04:17:13.991166Z","shell.execute_reply":"2024-03-19T04:17:25.815186Z"},"trusted":true},"execution_count":null,"outputs":[]},{"cell_type":"code","source":"import tarfile\n\ntry:\n    with tarfile.open('/kaggle/input/lfw-dataset/lfw-funneled.tgz', 'r') as tar:\n        tar.extractall(path='/kaggle/working/Dataset/Raw')\nexcept tarfile.TarError as e:\n    print(\"Failed\")","metadata":{"execution":{"iopub.status.busy":"2024-03-19T04:17:25.819337Z","iopub.execute_input":"2024-03-19T04:17:25.819666Z","iopub.status.idle":"2024-03-19T04:17:32.499081Z","shell.execute_reply.started":"2024-03-19T04:17:25.819639Z","shell.execute_reply":"2024-03-19T04:17:32.498150Z"},"trusted":true},"execution_count":null,"outputs":[]},{"cell_type":"code","source":"import math\nimport os\nimport random\nimport re\nimport shutil\nimport sys\nimport time\nfrom collections import Counter\nfrom typing import Any, Callable\n\nimport albumentations as A\nimport cv2\nimport imgaug\nimport keras\nimport matplotlib.image as mpimg\nimport matplotlib.pyplot as plt\nimport numpy as np\nimport tensorflow as tf\nimport tqdm\nfrom keras import backend as K\nfrom keras import layers, losses\nfrom keras.applications import MobileNet\nfrom keras.layers import (Activation, Conv2D, Dense, Dropout, GlobalAveragePooling2D, Flatten, Lambda,\n                          MaxPooling2D)\nfrom keras.models import Sequential, Model\nfrom keras.utils import to_categorical\nfrom PIL import Image\nfrom rich import print\nfrom sklearn.calibration import LabelEncoder\nfrom sklearn.model_selection import train_test_split\n","metadata":{"execution":{"iopub.status.busy":"2024-03-19T04:17:32.500325Z","iopub.execute_input":"2024-03-19T04:17:32.500692Z","iopub.status.idle":"2024-03-19T04:17:38.748218Z","shell.execute_reply.started":"2024-03-19T04:17:32.500665Z","shell.execute_reply":"2024-03-19T04:17:38.747216Z"},"trusted":true},"execution_count":null,"outputs":[]},{"cell_type":"code","source":"# !cp -r /kaggle/input/lfw-deepfunneled-with-mates /kaggle/working/lfw-deepfunneled-with-mates","metadata":{"execution":{"iopub.status.busy":"2024-03-19T04:17:38.749318Z","iopub.execute_input":"2024-03-19T04:17:38.749883Z","iopub.status.idle":"2024-03-19T04:17:38.754284Z","shell.execute_reply.started":"2024-03-19T04:17:38.749855Z","shell.execute_reply":"2024-03-19T04:17:38.753273Z"},"trusted":true},"execution_count":null,"outputs":[]},{"cell_type":"code","source":"# !cp -r /kaggle/input/mates-only-v2 /kaggle/working/mates-only-v2","metadata":{"execution":{"iopub.status.busy":"2024-03-19T04:17:38.756166Z","iopub.execute_input":"2024-03-19T04:17:38.756500Z","iopub.status.idle":"2024-03-19T04:17:38.768783Z","shell.execute_reply.started":"2024-03-19T04:17:38.756473Z","shell.execute_reply":"2024-03-19T04:17:38.767578Z"},"trusted":true},"execution_count":null,"outputs":[]},{"cell_type":"code","source":"SHUFFLE_NUMBER = 42","metadata":{"execution":{"iopub.status.busy":"2024-03-19T04:17:38.769987Z","iopub.execute_input":"2024-03-19T04:17:38.770267Z","iopub.status.idle":"2024-03-19T04:17:38.779147Z","shell.execute_reply.started":"2024-03-19T04:17:38.770243Z","shell.execute_reply":"2024-03-19T04:17:38.778206Z"},"trusted":true},"execution_count":null,"outputs":[]},{"cell_type":"code","source":"def identity(x):\n    return x\n\ndef swap(t):\n    return (t[1],t[0])","metadata":{"execution":{"iopub.status.busy":"2024-03-19T04:17:38.780292Z","iopub.execute_input":"2024-03-19T04:17:38.780569Z","iopub.status.idle":"2024-03-19T04:17:38.791642Z","shell.execute_reply.started":"2024-03-19T04:17:38.780545Z","shell.execute_reply":"2024-03-19T04:17:38.790736Z"},"trusted":true},"execution_count":null,"outputs":[]},{"cell_type":"code","source":"random.seed(SHUFFLE_NUMBER)\nimgaug.seed(SHUFFLE_NUMBER)","metadata":{"execution":{"iopub.status.busy":"2024-03-19T04:17:38.792731Z","iopub.execute_input":"2024-03-19T04:17:38.793486Z","iopub.status.idle":"2024-03-19T04:17:38.801151Z","shell.execute_reply.started":"2024-03-19T04:17:38.793454Z","shell.execute_reply":"2024-03-19T04:17:38.800260Z"},"trusted":true},"execution_count":null,"outputs":[]},{"cell_type":"code","source":"default_transform = A.Compose(\n    [\n#         A.RandomCrop(width=200, height=200),\n        A.RandomCropFromBorders (crop_left=0.1, crop_right=0.1, crop_top=0.1, crop_bottom=0.1),\n        A.HorizontalFlip(p=0.5),\n        # A.RandomScale(scale_limit=(-0.5, 2.0), p=0.5),\n        A.ShiftScaleRotate(p=0.5, shift_limit=0.1, scale_limit=0.2, rotate_limit=15),\n        A.RandomBrightnessContrast(p=0.2),\n        A.Blur(blur_limit=3, p=0.2),\n        A.Downscale(scale_min=0.35, scale_max=0.40, p=1)\n    ]\n)\n\n\ndef augment_data(\n    img: np.ndarray,\n    augmentation_count: int = 10,\n    augmentation_pipeline=None,\n    desired_shape: tuple[int, int] = (250, 250),\n) -> list[np.ndarray]:\n    images = []\n    if augmentation_pipeline is None:\n        augmentation_pipeline = default_transform\n    for _ in range(augmentation_count):\n        aug_image = augmentation_pipeline(image=img)[\"image\"]\n        aug_image = Image.fromarray(aug_image).resize(desired_shape)\n        aug_image = np.array(aug_image)\n        images.append(aug_image)\n    return images\n","metadata":{"execution":{"iopub.status.busy":"2024-03-19T04:17:38.802259Z","iopub.execute_input":"2024-03-19T04:17:38.802524Z","iopub.status.idle":"2024-03-19T04:17:38.814724Z","shell.execute_reply.started":"2024-03-19T04:17:38.802501Z","shell.execute_reply":"2024-03-19T04:17:38.813862Z"},"trusted":true},"execution_count":null,"outputs":[]},{"cell_type":"code","source":"","metadata":{"trusted":true},"execution_count":null,"outputs":[]},{"cell_type":"code","source":"class LazyData:\n    face_cascade = cv2.CascadeClassifier(cv2.data.haarcascades + 'haarcascade_frontalface_default.xml')\n    \n    def __init__(\n        self,\n        filename: str,\n        load_strategy: str | Callable[[str | bytes], Any] | None = None,\n        *args,\n        **kwargs,\n    ):\n        self._filename = filename\n        self._data = None\n        self._load_strategy = load_strategy\n        self._args = args\n        self._kwargs = kwargs\n\n    def __call__(self):\n        if self._data is None:\n            self._build_data()\n        return self._data\n\n    def __load_strategy_image(self, buf) -> np.ndarray[np.uint8]:\n        img = mpimg.imread(buf, format=\"jpg\")\n        if self._kwargs.get(\"desired_shape\") is not None:\n            pilimg = Image.fromarray(img).resize(self._kwargs.get(\"desired_shape\"), Image.ANTIALIAS)\n            img = np.array(pilimg)\n        return img\n    \n    def __load_strategy_image_face(self, buf) -> np.ndarray[np.uint8]:\n        img = mpimg.imread(buf, format=\"jpg\")\n#         print(\"__load_strategy_image_face\")\n        if self._kwargs.get(\"desired_shape\") is not None:\n            desired_shape = self._kwargs.get(\"desired_shape\")\n            if desired_shape[0] > img.shape[0] or desired_shape[1] > img.shape[1]:\n#                 print(\"Failure point 1: Desired Shape can't be fit inside image\")\n#                 print(f\"{desired_shape[0] = }, {desired_shape[1] = }\")\n#                 print(f\"{img.shape[0] = }, {img.shape[1] = }\")\n                return img\n            \n            image = img.copy()\n            faces = LazyData.face_cascade.detectMultiScale(image, scaleFactor=1.1, minNeighbors=5, minSize=(30, 30))\n            if len(faces) > 0:\n                x, y, w, h = faces[0]\n            else:\n                x, y, w, h = 0, 0, img.shape[1], img.shape[0]\n            \n            cx, cy = (x + x + w)//2, (y + y + h)//2\n            nw, nh = desired_shape[1], desired_shape[0]\n            exw, exh = w, h\n            \n            if nw < w:\n                exw = nw\n            if nh < h:\n                exh = nh\n            if nw > w:\n                lb = cx - nw//2\n                rb = cx + nw//2\n                if lb < 0 and rb > img.shape[1]:\n                    raise Exception(\"AbsurdError: Desired shape greater than image\")\n                elif lb < 0:\n                    cx += -lb\n                elif rb > img.shape[1]:\n                    cx -= (rb - img.shape[1])\n            if nh > h:\n                ub = cy - nh//2\n                db = cy + nh//2\n                if ub < 0 and db > img.shape[0]:\n                    raise Exception(\"AbsurdError: Desired shape greater than image\")\n                elif ub < 0:\n                    cy += -ub\n                elif db > img.shape[0]:\n                    cy -= (db - img.shape[0])\n            \n            new_img = img[(cy-nh//2):(cy+nh//2), (cx-nw//2):(cx+nw//2)]\n            \n            # possible off by ones correction\n            pilimg = Image.fromarray(img).resize(swap(desired_shape), Image.ANTIALIAS)\n            img = np.array(pilimg)\n#         print(img.shape)\n        return img\n            \n    def _build_data(self):\n        with open(self._filename, \"rb\") as f:\n            if self._load_strategy is None:\n                self._data = f.read()\n            elif self._load_strategy == \"image\":\n                self._data = self.__load_strategy_image(self._filename)\n            elif self._load_strategy == \"image_face\":\n                self._data = self.__load_strategy_image_face(self._filename)\n            else:\n                buf = f.read()\n                self._data = self._load_strategy(buf)","metadata":{"execution":{"iopub.status.busy":"2024-03-19T04:17:38.816380Z","iopub.execute_input":"2024-03-19T04:17:38.816788Z","iopub.status.idle":"2024-03-19T04:17:38.858209Z","shell.execute_reply.started":"2024-03-19T04:17:38.816759Z","shell.execute_reply":"2024-03-19T04:17:38.857516Z"},"trusted":true},"execution_count":null,"outputs":[]},{"cell_type":"code","source":"def dataset(\n    path: str,\n    min_faces: int | None = 20,\n    max_faces: int | None = None,\n    hard_limit: bool = False,\n    shuffle: bool = True,\n    random_state: int | None = None,\n    verbose: bool | None = True,\n    desired_shape: tuple[int,int] = (250,250)\n):\n    if random_state is not None:\n        np.random.seed(random_state)\n\n    excluded_dirs = []\n    capped_dirs = []\n    capped_counts = {}\n    for direc in os.listdir(path):\n        if os.path.isdir(os.path.join(path, direc)):\n            if min_faces is not None:\n                if len(os.listdir(os.path.join(path, direc))) < min_faces:\n                    excluded_dirs.append(direc)\n            if max_faces is not None:\n                if len(os.listdir(os.path.join(path, direc))) > max_faces:\n                    if hard_limit:\n                        excluded_dirs.append(direc)\n                    else:\n                        capped_dirs.append(direc)\n\n    ds = []\n    tracker = tqdm.tqdm if verbose else identity\n    pattern = re.compile(r\"(.*)_(?:\\d+)\\.jpg\")\n\n    for root, dirs, files in tracker(os.walk(path)):\n        for file in files:\n            if file.endswith(\".jpg\"):\n                match = pattern.match(file)\n                if match:\n                    target = match.group(1)\n\n                    if target in excluded_dirs:\n                        continue\n\n                    if max_faces is not None:\n                        if target in capped_dirs:\n                            if target not in capped_counts:\n                                capped_counts[target] = 0\n                            capped_counts[target] += 1\n                            if capped_counts[target] > max_faces:\n                                continue\n\n                    ds.append(\n                        [\n                            LazyData(\n                                os.path.abspath(os.path.join(root, file)),\n                                load_strategy=\"image_face\",\n                                desired_shape=desired_shape\n                            ),\n                            target,\n                        ]\n                    )\n\n    if shuffle:\n        np.random.shuffle(ds)\n\n    return np.array(ds)\n\n\ndef fetch_lfw_people(\n    path_to_dataset: str = \"Dataset/Raw\",\n    min_faces: int | None = 20,\n    max_faces: int | None = None,\n    hard_limit: bool = False,\n    shuffle: bool = True,\n    random_state: int | None = None,\n    verbose: bool = True,\n    desired_shape: tuple[int,int] = (250, 250)\n):\n    dst = dataset(\n        path_to_dataset,\n        min_faces=min_faces,\n        max_faces=max_faces,\n        hard_limit=hard_limit,\n        shuffle=shuffle,\n        random_state=random_state,\n        verbose=verbose,\n        desired_shape=desired_shape,\n    )\n    X = dst[:, 0]\n    Y = dst[:, 1]\n    return X, Y\n","metadata":{"execution":{"iopub.status.busy":"2024-03-19T04:17:38.862365Z","iopub.execute_input":"2024-03-19T04:17:38.862947Z","iopub.status.idle":"2024-03-19T04:17:38.878726Z","shell.execute_reply.started":"2024-03-19T04:17:38.862923Z","shell.execute_reply":"2024-03-19T04:17:38.877870Z"},"trusted":true},"execution_count":null,"outputs":[]},{"cell_type":"code","source":"def visualize_image(axes_array, images_array, labels_array, figure):\n    axes_array = axes_array.flatten()\n\n    # assert len(axes_array) == len(images_array) == len(labels_array)\n    assert len(axes_array) <= len(images_array)\n    assert len(axes_array) <= len(labels_array)\n\n    for i, ax in enumerate(axes_array):\n        img = ax.imshow(images_array[i], cmap=\"gray\")\n        figure.colorbar(img, ax=ax)\n        ax.set_title(labels_array[i])\n        ax.axis(\"off\")\n","metadata":{"execution":{"iopub.status.busy":"2024-03-19T04:17:38.879773Z","iopub.execute_input":"2024-03-19T04:17:38.880018Z","iopub.status.idle":"2024-03-19T04:17:38.892981Z","shell.execute_reply.started":"2024-03-19T04:17:38.879997Z","shell.execute_reply":"2024-03-19T04:17:38.892184Z"},"trusted":true},"execution_count":null,"outputs":[]},{"cell_type":"code","source":"\n\n# TODO: Documentation\n\n\ndef dump_test_files(x_test, y_test, path_prefix: str, verbose=True):\n    # clear out the directory\n    if os.path.exists(path_prefix):\n        shutil.rmtree(path_prefix)\n\n    if os.path.exists(path_prefix + \".zip\"):\n        os.remove(path_prefix + \".zip\")\n\n    os.makedirs(path_prefix)\n\n    freq_table = {}\n    for i, x in enumerate(x_test):\n        target = y_test[i]\n        if target not in freq_table:\n            freq_table[target] = 0\n            os.makedirs(os.path.join(path_prefix, str(target)))\n        freq_table[target] += 1\n\n        # write image as jpeg\n        Image.fromarray(x).save(\n            os.path.join(\n                path_prefix, str(target), f\"{target}_{freq_table[target]:04}.jpg\"\n            )\n        )\n\n    shutil.make_archive(path_prefix, \"zip\", path_prefix)\n    if verbose:\n        print(\"[bold green]Test files dumped successfully[/bold green]\")\n\n    shutil.rmtree(os.path.join(path_prefix))\n\n\ndef export_dataset_objects(\n    path_to_dataset: str = \"Dataset/Raw\",\n    min_faces: int | None = 20,\n    max_faces: int | None = None,\n    hard_limit: bool = False,\n    shuffle=True,\n    random_state=None,\n    test_size=0.2,\n    verbose=True,\n    augment=True,\n    desired_shape: tuple[int, int] = (250, 250),\n    augmentation_count: int = 10,\n    augmentation_upto: int | None = None,\n    augmentation_pipeline=None,\n    experimental_export: bool = True,\n    export: bool = True,\n):\n    X, Y = fetch_lfw_people(\n        path_to_dataset=path_to_dataset,\n        min_faces=min_faces,\n        max_faces=max_faces,\n        hard_limit=hard_limit,\n        shuffle=shuffle,\n        random_state=random_state,\n        verbose=verbose,\n        desired_shape=desired_shape,\n    )\n\n    log = print if verbose else identity\n\n    log(\"[bold green]Dataset loaded successfully[/bold green]\")\n\n    export_path = os.path.dirname(path_to_dataset)\n\n    tracker = tqdm.tqdm if verbose else identity\n\n    # print(sys.getsizeof(X[0]))\n    # exit(1)\n\n    __x = []\n    for x in tracker(X):\n        __x.append(x())\n    # # exit(1)\n\n    __x = np.array(__x, copy=False)\n    log(\"[bold green]Binary data loaded successfully[/bold green]\")\n    # __x = np.zeros((X.shape[0], 250, 250, 3), dtype=np.uint8)\n    # print(__x.shape)\n    # for i, x in tracker(enumerate(X)):\n    #     __x[i] = x()\n\n    x_train, x_test, y_train, y_test = train_test_split(\n        __x,\n        Y,\n        test_size=test_size,\n        random_state=random_state,\n        stratify=Y,\n    )\n\n    log(\"[bold green]Dataset split successfully[/bold green]\")\n\n    if augment:\n        if augmentation_upto is None:\n            xy = []\n            for i, x in tracker(enumerate(x_train)):\n                aug_data = augment_data(\n                    x,\n                    desired_shape=desired_shape,\n                    augmentation_count=augmentation_count,\n                    augmentation_pipeline=augmentation_pipeline,\n                )\n\n                for data in aug_data:\n#                     data = Image.fromarray(data).convert(\"L\")\n#                     data = np.array(data, copy=False)\n                    xy.append([data, y_train[i]])\n                # print(xy)\n                # fig, axes = plt.subplots(2, 5, figsize=(20, 10))\n                # axes = axes.flatten()\n\n                # for img, ax in zip(aug_data, axes):\n                #     ax.imshow(img)\n                #     ax.axis(\"off\")\n                # plt.tight_layout()\n                # plt.show()\n\n                # exit(1)\n            log(\"[bold green]Augmentation done successfully[/bold green]\")\n            xy_data = np.array(xy, dtype=object, copy=False)\n            print(xy_data.shape)\n            log(\"[bold green]Augmented data converted to numpy array[/bold green]\")\n            if shuffle:\n                np.random.shuffle(xy_data)\n                log(\"[bold green]Augmented data shuffled successfully[/bold green]\")\n\n            x_train_data = xy_data[:, 0]\n            log(\"[bold green]x_train_data split successfully[/bold green]\")\n            y_train_data = xy_data[:, 1]\n            log(\"[bold green]y_train_data split successfully[/bold green]\")\n#             x_train_data = x_train_data / 255\n            log(\"[bold green]x_train_data normalized successfully[/bold green]\")\n#             x_test = x_test / 255\n            log(\"[bold green]x_test normalized successfully[/bold green]\")\n            if export:\n                if not experimental_export:\n                    x_train_data.dump(os.path.join(export_path, \"x_train.npy\"))\n                    y_train_data.dump(os.path.join(export_path, \"y_train.npy\"))\n                    x_test.dump(os.path.join(export_path, \"x_test.npy\"))\n                    y_test.dump(os.path.join(export_path, \"y_test.npy\"))\n                else:\n                    np.savez_compressed(\n                        os.path.join(export_path, \"data.npz\"),\n                        x_train=x_train_data,\n                        y_train=y_train_data,\n                        x_test=x_test,\n                        y_test=y_test,\n                    )\n                    log(\"[bold green]Dataset exported successfully[/bold green]\")\n\n            # og_data = np.array(__x)\n            # og_data.dump(\"Dataset/x_og.npy\")\n            # y_data.dump(\"Dataset/y.npy\")\n        else:\n            xy = []\n            idents = {}\n            for i, y in enumerate(y_train):\n                if y in idents:\n                    idents[y].append(i)\n                else:\n                    idents[y] = [i]\n            log(\"[bold green]Identified classes successfully[/bold green]\")\n\n            if augmentation_upto == 0:\n                # augment upto max_faces\n                if max_faces is None:\n                    raise Exception(\"max_faces must be int if augmentation_upto is 0\")\n\n                for y in idents:\n                    augmentation_len = max_faces - len(idents[y])\n                    for _k in range(augmentation_len):\n                        # choose random image\n                        random_image = np.random.choice(idents[y])\n                        # augment it\n                        aug_data = augment_data(\n                            x_train[random_image],\n                            desired_shape=desired_shape,\n                            augmentation_count=1,\n                            augmentation_pipeline=augmentation_pipeline,\n                        )\n                        aug_image = aug_data[0]\n#                         aug_image = Image.fromarray(aug_image).convert(\"L\")\n#                         aug_image = np.array(aug_image, copy=False)\n                        # add it to the dataset\n                        xy.append([aug_image, y])\n                    log(\n                        \"[bold green]Augmented upto max_faces successfully[/bold green]\"\n                    )\n            elif augmentation_upto > 0:\n                # augment upto augmentation_upto\n                for y in idents:\n                    faces = len(idents[y])\n                    if augmentation_upto > faces:\n                        augmentation_len = augmentation_upto - len(idents[y])\n                        for _k in range(augmentation_len):\n                            # choose random image\n                            random_image = np.random.choice(idents[y])\n                            # augment it\n                            aug_data = augment_data(\n                                x_train[random_image],\n                                desired_shape=desired_shape,\n                                augmentation_count=1,\n                                augmentation_pipeline=augmentation_pipeline,\n                            )\n                            aug_image = aug_data[0]\n#                             aug_image = Image.fromarray(aug_image).convert(\"L\")\n#                             aug_image = np.array(aug_image, copy=False)\n                            # add it to the dataset\n                            xy.append([aug_image, y])\n                log(\n                    \"[bold green]Augmented upto augmentation_upto successfully[/bold green]\"\n                )\n            else:\n                raise Exception(\"augmentation_upto must be bool or int\")\n\n            # add the original image with the label\n            for i, x in tracker(enumerate(x_train)):\n                cv_image = x\n#                 cv_image = Image.fromarray(cv_image).convert(\"L\")\n#                 cv_image = np.array(cv_image, copy=False)\n                xy.append([cv_image, y_train[i]])\n            log(\"[bold green]Original images added successfully[/bold green]\")\n\n            xy_data = np.array(xy, dtype=object, copy=False)\n            print(xy_data.shape)\n            log(\"[bold green]Augmented data converted to numpy array[/bold green]\")\n            if shuffle:\n                np.random.shuffle(xy_data)\n                log(\"[bold green]Augmented data shuffled successfully[/bold green]\")\n            x_train_data = xy_data[:, 0]\n            print(x_train_data.shape)\n            log(\"[bold green]x_train_data split successfully[/bold green]\")\n            y_train_data = xy_data[:, 1]\n            print(y_train_data.shape)\n            log(\"[bold green]y_train_data split successfully[/bold green]\")\n#             x_train_data = x_train_data / 255\n            log(\"[bold green]x_train_data normalized successfully[/bold green]\")\n#             x_test = x_test / 255\n            log(\"[bold green]x_test normalized successfully[/bold green]\")\n\n            if export:\n                if not experimental_export:\n                    x_train_data.dump(os.path.join(export_path, \"x_train.npy\"))\n                    y_train_data.dump(os.path.join(export_path, \"y_train.npy\"))\n                    x_test.dump(os.path.join(export_path, \"x_test.npy\"))\n                    y_test.dump(os.path.join(export_path, \"y_test.npy\"))\n                else:\n                    np.savez_compressed(\n                        os.path.join(export_path, \"data.npz\"),\n                        x_train=x_train_data,\n                        y_train=y_train_data,\n                        x_test=x_test,\n                        y_test=y_test,\n                    )\n                    log(\"[bold green]Dataset exported successfully[/bold green]\")\n\n    else:\n        # x_data = np.array(__x)\n        # x_data.dump(\"Dataset/x.npy\")\n        # Y.dump(\"Dataset/y.npy\")\n#         x_train = x_train / 255\n#         x_test = x_test / 255\n        if export:\n            if not experimental_export:\n                x_train.dump(os.path.join(export_path, \"x_train.npy\"))\n                y_train.dump(os.path.join(export_path, \"y_train.npy\"))\n                x_test.dump(os.path.join(export_path, \"x_test.npy\"))\n                y_test.dump(os.path.join(export_path, \"y_test.npy\"))\n            else:\n                np.savez_compressed(\n                    os.path.join(export_path, \"data.npz\"),\n                    x_train=x_train,\n                    y_train=y_train,\n                    x_test=x_test,\n                    y_test=y_test,\n                )\n\n\nif __name__ == \"__main__\":\n    export_dataset_objects(\n        path_to_dataset=\"/kaggle/working/Dataset/Raw/lfw_funneled\",\n        shuffle=True,\n        random_state=SHUFFLE_NUMBER,\n        min_faces=20,\n        max_faces=60,\n        hard_limit=False,\n        augment=True,\n        augmentation_upto=100,\n        experimental_export=True,\n        test_size=0.3,\n        desired_shape=(250,250),\n        export=True,\n    )\n","metadata":{"execution":{"iopub.status.busy":"2024-03-19T04:17:38.894187Z","iopub.execute_input":"2024-03-19T04:17:38.894523Z","iopub.status.idle":"2024-03-19T04:19:17.736874Z","shell.execute_reply.started":"2024-03-19T04:17:38.894499Z","shell.execute_reply":"2024-03-19T04:19:17.735848Z"},"trusted":true},"execution_count":null,"outputs":[]},{"cell_type":"code","source":"","metadata":{"trusted":true},"execution_count":null,"outputs":[]},{"cell_type":"code","source":"# !ls /kaggle/working/lfw-deepfunneled-with-mates | grep --color=always \"data.npz\"","metadata":{"execution":{"iopub.status.busy":"2024-03-19T04:19:17.738076Z","iopub.execute_input":"2024-03-19T04:19:17.738364Z","iopub.status.idle":"2024-03-19T04:19:17.742705Z","shell.execute_reply.started":"2024-03-19T04:19:17.738341Z","shell.execute_reply":"2024-03-19T04:19:17.741671Z"},"trusted":true},"execution_count":null,"outputs":[]},{"cell_type":"code","source":"import numpy as np \ndata = np.load(\"/kaggle/working/Dataset/Raw/data.npz\", allow_pickle=True)\nX = data['x_train']\nY = data['y_train']\nx_test = data['x_test']\ny_test = data['y_test']","metadata":{"execution":{"iopub.status.busy":"2024-03-19T04:19:17.743966Z","iopub.execute_input":"2024-03-19T04:19:17.744235Z","iopub.status.idle":"2024-03-19T04:19:25.547525Z","shell.execute_reply.started":"2024-03-19T04:19:17.744212Z","shell.execute_reply":"2024-03-19T04:19:25.546714Z"},"trusted":true},"execution_count":null,"outputs":[]},{"cell_type":"code","source":"from collections import Counter\n\nlabel_counts = Counter(Y)\n\nfor label, count in label_counts.items():\n    print(f\"Label {label}: {count} images\")\n","metadata":{"execution":{"iopub.status.busy":"2024-03-19T04:19:25.548667Z","iopub.execute_input":"2024-03-19T04:19:25.548950Z","iopub.status.idle":"2024-03-19T04:19:25.663822Z","shell.execute_reply.started":"2024-03-19T04:19:25.548927Z","shell.execute_reply":"2024-03-19T04:19:25.662963Z"},"trusted":true},"execution_count":null,"outputs":[]},{"cell_type":"code","source":"import numpy as np\n\nunique_identities = np.unique(Y)\nn_unique_identities = len(unique_identities)\n\nprint(f\"There are {len(unique_identities)} unique identities.\")","metadata":{"execution":{"iopub.status.busy":"2024-03-19T04:19:25.664803Z","iopub.execute_input":"2024-03-19T04:19:25.665046Z","iopub.status.idle":"2024-03-19T04:19:25.677354Z","shell.execute_reply.started":"2024-03-19T04:19:25.665025Z","shell.execute_reply":"2024-03-19T04:19:25.676322Z"},"trusted":true},"execution_count":null,"outputs":[]},{"cell_type":"code","source":"from collections import Counter\n\nlabel_counts = Counter(Y)\n\n# Find the identity with the least number of images\nmin_label, min_count = min(label_counts.items(), key=lambda x: x[1])\n\nprint(f\"Identity {min_label} has the least number of images: {min_count} images\")\n","metadata":{"execution":{"iopub.status.busy":"2024-03-19T04:19:25.678542Z","iopub.execute_input":"2024-03-19T04:19:25.678825Z","iopub.status.idle":"2024-03-19T04:19:25.689993Z","shell.execute_reply.started":"2024-03-19T04:19:25.678802Z","shell.execute_reply":"2024-03-19T04:19:25.689179Z"},"trusted":true},"execution_count":null,"outputs":[]},{"cell_type":"code","source":"X.shape","metadata":{"execution":{"iopub.status.busy":"2024-03-19T04:19:25.690887Z","iopub.execute_input":"2024-03-19T04:19:25.691141Z","iopub.status.idle":"2024-03-19T04:19:25.703515Z","shell.execute_reply.started":"2024-03-19T04:19:25.691120Z","shell.execute_reply":"2024-03-19T04:19:25.702683Z"},"trusted":true},"execution_count":null,"outputs":[]},{"cell_type":"code","source":"x_test.shape","metadata":{"execution":{"iopub.status.busy":"2024-03-19T04:19:25.704627Z","iopub.execute_input":"2024-03-19T04:19:25.704920Z","iopub.status.idle":"2024-03-19T04:19:25.713922Z","shell.execute_reply.started":"2024-03-19T04:19:25.704878Z","shell.execute_reply":"2024-03-19T04:19:25.713033Z"},"trusted":true},"execution_count":null,"outputs":[]},{"cell_type":"code","source":"import matplotlib.pyplot as plt\n\n# Function to plot images\ndef plot_images(images, title):\n    plt.figure(figsize=(10,10))\n    for i in range(5):\n        plt.subplot(1,5,i+1)\n        plt.xticks([])\n        plt.yticks([])\n        plt.grid(False)\n        plt.imshow(images[i], cmap=plt.cm.binary)\n        plt.xlabel(title)\n    plt.show()\n\n# Plot images from X\nplot_images(X, \"X\")\n\n# Plot images from x_test\nplot_images(x_test, \"x_test\")\n","metadata":{"execution":{"iopub.status.busy":"2024-03-19T04:19:25.715228Z","iopub.execute_input":"2024-03-19T04:19:25.715564Z","iopub.status.idle":"2024-03-19T04:19:26.356319Z","shell.execute_reply.started":"2024-03-19T04:19:25.715534Z","shell.execute_reply":"2024-03-19T04:19:26.355358Z"},"trusted":true},"execution_count":null,"outputs":[]},{"cell_type":"code","source":"import cv2\nimport matplotlib.pyplot as plt\n\ndef detect_faces_in_image(input_image):\n    # Initialize face detector\n    face_cascade = cv2.CascadeClassifier(cv2.data.haarcascades + 'haarcascade_frontalface_default.xml')\n\n    image = input_image.copy()\n#     # Convert the image to 8-bit\n#     image = cv2.convertScaleAbs(input_image)\n    \n#     # Check if the image is already grayscale\n#     if len(image.shape) == 3:\n#         # Convert the image to grayscale\n#         gray = cv2.cvtColor(image, cv2.COLOR_BGR2GRAY)\n#     else:\n#         gray = image\n    \n    # Detect faces in the image\n    faces = face_cascade.detectMultiScale(image, scaleFactor=1.1,  minNeighbors=5, minSize=(30, 30))\n    \n    for (x, y, w, h) in faces:\n        # Draw a rectangle around the face\n        cv2.rectangle(image, (x, y), (x+w, y+h), (0, 255, 0), 2)\n        \n    return image\n        \n\nimg_faces_train = [\n    detect_faces_in_image(image) for i, image in enumerate(X) if i < 5\n]\nimg_faces_test = [\n    detect_faces_in_image(image) for i, image in enumerate(x_test) if i < 5\n]\n\nfig, axes = plt.subplots(2, 5, figsize=(40, 10))\naxes = axes.flatten()\nfor i in range(10):\n    if i < 5:\n        ax = axes[i]\n        ax.imshow(img_faces_train[i], cmap=\"gray\")\n        ax.axis(\"off\")\n    else:\n        ax = axes[i]\n        ax.imshow(img_faces_test[i - 5])\n        ax.axis(\"off\")\nplt.tight_layout()\nplt.show()\n","metadata":{"execution":{"iopub.status.busy":"2024-03-19T04:19:26.357992Z","iopub.execute_input":"2024-03-19T04:19:26.358298Z","iopub.status.idle":"2024-03-19T04:19:28.476091Z","shell.execute_reply.started":"2024-03-19T04:19:26.358272Z","shell.execute_reply":"2024-03-19T04:19:28.474687Z"},"trusted":true},"execution_count":null,"outputs":[]},{"cell_type":"code","source":"print(x_test[0].dtype)\n","metadata":{"execution":{"iopub.status.busy":"2024-03-19T04:19:28.477491Z","iopub.execute_input":"2024-03-19T04:19:28.477794Z","iopub.status.idle":"2024-03-19T04:19:28.483953Z","shell.execute_reply.started":"2024-03-19T04:19:28.477769Z","shell.execute_reply":"2024-03-19T04:19:28.482969Z"},"trusted":true},"execution_count":null,"outputs":[]},{"cell_type":"markdown","source":"# crop the face","metadata":{}},{"cell_type":"code","source":"import cv2\nimport matplotlib.pyplot as plt\n\ndef detect_and_crop_faces_in_image(input_image):\n    face_cascade = cv2.CascadeClassifier(cv2.data.haarcascades + 'haarcascade_frontalface_default.xml')\n\n    image = input_image.copy()\n#     # Convert the image to 8-bit\n#     image = cv2.convertScaleAbs(input_image)\n    \n#     # Check if the image is already grayscale\n#     if len(image.shape) == 2:\n#         image = cv2.cvtColor(image, cv2.COLOR_GRAY2BGR)\n    \n#     gray = cv2.cvtColor(image, cv2.COLOR_BGR2GRAY)\n    \n    faces = face_cascade.detectMultiScale(image, scaleFactor=1.1, minNeighbors=5, minSize=(30, 30))\n    \n    # If a face is detected, crop it out\n    if len(faces) > 0:\n        x, y, w, h = faces[0]\n        cropped_face = image[y:y+h, x:x+w]\n    else:\n        cropped_face = image\n\n    # Resize the cropped face or the original image to (227, 227)\n    resized_image = cv2.resize(cropped_face, (224, 224))\n    return resized_image\n\ncropped_face_X = []\ncropped_face_x_test = []\n\n# from multiprocessing import Pool\n\n# with Pool(4) as pool:\ntracker = tqdm.tqdm\n#     cropped_face_X = pool.map_async(detect_and_crop_faces_in_image, tracker(X)).get()\n#     cropped_face_x_test = pool.map_async(detect_and_crop_faces_in_image, tracker(x_test)).get()\n\nfor image in tracker(X):\n    cropped_face = detect_and_crop_faces_in_image(image)\n    cropped_face_X.append(cropped_face) \n\nfor image in tracker(x_test):\n    cropped_face = detect_and_crop_faces_in_image(image)\n    cropped_face_x_test.append(cropped_face)","metadata":{"execution":{"iopub.status.busy":"2024-03-19T04:19:28.485099Z","iopub.execute_input":"2024-03-19T04:19:28.485363Z","iopub.status.idle":"2024-03-19T04:23:39.598668Z","shell.execute_reply.started":"2024-03-19T04:19:28.485339Z","shell.execute_reply":"2024-03-19T04:23:39.597743Z"},"trusted":true},"execution_count":null,"outputs":[]},{"cell_type":"code","source":"fig, axes = plt.subplots(2, 5, figsize=(40, 10))\naxes = axes.flatten()\nfor i in range(10):\n    if i < 5:\n        ax = axes[i]\n        ax.imshow(cropped_face_X[i], cmap=\"gray\")\n        ax.axis(\"off\")\n    else:\n        ax = axes[i]\n        ax.imshow(cropped_face_x_test[i - 5])\n        ax.axis(\"off\")\nplt.tight_layout()\nplt.show()","metadata":{"execution":{"iopub.status.busy":"2024-03-19T04:23:39.599739Z","iopub.execute_input":"2024-03-19T04:23:39.600000Z","iopub.status.idle":"2024-03-19T04:23:41.662169Z","shell.execute_reply.started":"2024-03-19T04:23:39.599979Z","shell.execute_reply":"2024-03-19T04:23:41.661153Z"},"trusted":true},"execution_count":null,"outputs":[]},{"cell_type":"code","source":"import tensorflow as tf\nfrom keras import backend as K\nimport cv2\nimport numpy as np\nimport keras\nfrom keras.models import Sequential\nfrom keras import layers, losses\nfrom keras.layers import Conv2D, MaxPooling2D, Flatten, Dense, Lambda, Activation\nfrom keras.utils import to_categorical\nfrom sklearn.calibration import LabelEncoder\n\nunique_identities = np.unique(Y)\n\n# Check if GPU is available and if not, set the CPU as device\nif tf.test.gpu_device_name():\n    print('Default GPU Device: {}'.format(tf.test.gpu_device_name()))\nelse:\n    print(\"Please install GPU version of TF\")\n\n# def normalize_images(image_array):\n#     # Normalize the images \n#     for i, image in enumerate(image_array):\n#         image = ((image - np.min(image)) / (np.max(image) - np.min(image)))\n#         image_array[i] = image\n#     return image_array\n\ndef normalize_image(image):\n    return ((image - tf.math.reduce_min(image)) / (tf.math.reduce_max(image) - tf.math.reduce_min(image)))\n\n# # Apply the function to our final_X and final_x_test \n# final_X = normalize_images(cropped_face_X)\n# final_x_test = normalize_images(cropped_face_x_test)\n\n# Convert lists to Numpy arrays\n# final_X = np.array(final_X)\n# final_x_test = np.array(final_x_test)\n\n\n# X_data = tf.data.Dataset.from_generator(iter(cropped_face_X))\n# x_test_data = tf.data.Dataset.from_generator(iter(cropped_face_x_test))\n\n# final_X = X_data.apply(normalize_image)\n# final_x_test = x_test_data.apply(normalize_image)\n\n# Initialize the label encoder\nle = LabelEncoder()\n\n# Fit the label encoder and transform the labels\nY_int = le.fit_transform(Y)\nprint(Y_int)\n\nY_one_hot = to_categorical(Y_int, num_classes=n_unique_identities)\n\ndataset_size = int(len(cropped_face_X))\n\ntrain_val_data = tf.data.Dataset.from_tensor_slices((cropped_face_X, Y_one_hot))\nprint(\"created tensor slice\")\ntrain_val_data = train_val_data.map(lambda x, y: (normalize_image(x), y))\nprint(\"added mapping\")\n\ntrain_val_data = train_val_data.shuffle(5000)\nprint(\"shuffled\")\ntrain_data = train_val_data.take(int(0.9 * dataset_size)).batch(32)\nprint(\"train data\")\nval_data = train_val_data.skip(int(0.9 * dataset_size)).batch(32)\nprint(\"val data\")","metadata":{"execution":{"iopub.status.busy":"2024-03-19T04:23:41.663417Z","iopub.execute_input":"2024-03-19T04:23:41.663738Z","iopub.status.idle":"2024-03-19T04:33:46.636166Z","shell.execute_reply.started":"2024-03-19T04:23:41.663709Z","shell.execute_reply":"2024-03-19T04:33:46.635263Z"},"trusted":true},"execution_count":null,"outputs":[]},{"cell_type":"code","source":"# import keras_tuner as kt\n# class MyHypermodel(kt.applications.HyperResNet):\n#     def __init__(\n#         self,\n#         include_top=True,\n#         input_shape=None,\n#         input_tensor=None,\n#         classes=None,\n#         **kwargs,\n#     ):\n#         super().__init__(include_top, input_shape, input_tensor, **kwargs)\n\n#     def build(self, hp):\n#         model = super().build(hp)\n# #         model = layers.Dense(n_unique_identities, activation='softmax')(model)\n        \n#         inp = model.layers[0].input\n#         x = model.layers[-1].output\n#         x = layers.Dense(n_unique_identities, activation='softmax', name='predictions')(x)\n#         model = keras.Model(inputs=inp, outputs=x)\n\n#         hp_learning_rate = hp.Choice('learning_rate', values=[1e-2, 5e-3, 1e-3, 5e-4, 1e-4, 5e-5, 1e-5])\n\n#         model.compile(optimizer=tf.keras.optimizers.Adam(hp_learning_rate),\n#                      loss=tf.keras.losses.categorical_crossentropy,\n#                      metrics=['accuracy'])\n#         return model\n    \n#     def fit(self, hp, model, *args, **kwargs):\n#         history = model.fit(*args, **kwargs)\n#         return {\n#             \"loss\": history.history[\"loss\"],\n#             \"accuracy\": history.history[\"accuracy\"],\n#             \"val_loss\": history.history[\"val_loss\"],\n#             \"val_accuracy\": history.history[\"val_accuracy\"]\n#         }","metadata":{"execution":{"iopub.status.busy":"2024-03-19T04:33:46.637855Z","iopub.execute_input":"2024-03-19T04:33:46.638270Z","iopub.status.idle":"2024-03-19T04:33:46.643272Z","shell.execute_reply.started":"2024-03-19T04:33:46.638231Z","shell.execute_reply":"2024-03-19T04:33:46.642455Z"},"trusted":true},"execution_count":null,"outputs":[]},{"cell_type":"code","source":"# def get_hypermodel():\n#     hypermodel = kt.applications.HyperResNet(\n#         include_top=False, input_shape=(256, 256, 3), input_tensor=None, classes=n_unique_identities\n#     )\n    \n#     return hypermodel","metadata":{"execution":{"iopub.status.busy":"2024-03-19T04:33:46.644438Z","iopub.execute_input":"2024-03-19T04:33:46.644758Z","iopub.status.idle":"2024-03-19T04:33:46.660218Z","shell.execute_reply.started":"2024-03-19T04:33:46.644727Z","shell.execute_reply":"2024-03-19T04:33:46.659352Z"},"trusted":true},"execution_count":null,"outputs":[]},{"cell_type":"code","source":"# def build_model(hp):\n#     model = get_hypermodel()\n#     model = layers.Dense(n_unique_identities, activation='softmax')(model)\n    \n#     hp_learning_rate = hp.Choice('learning_rate', values=[1e-2, 5e-3, 1e-3, 5e-4, 1e-4, 5e-5, 1e-5])\n    \n#     model.compile(optimizer=tf.keras.optimizers.Adam(hp_learning_rate),\n#                  loss=tf.keras.losses.categorical_crossentropy,\n#                  metrics=['accuracy'])\n#     return model\n","metadata":{"execution":{"iopub.status.busy":"2024-03-19T04:33:46.661258Z","iopub.execute_input":"2024-03-19T04:33:46.661916Z","iopub.status.idle":"2024-03-19T04:33:46.670857Z","shell.execute_reply.started":"2024-03-19T04:33:46.661891Z","shell.execute_reply":"2024-03-19T04:33:46.670055Z"},"trusted":true},"execution_count":null,"outputs":[]},{"cell_type":"code","source":"# hp = kt.HyperParameters()\n# hp.Choice('learning_rate', values=[1e-2, 5e-3, 1e-3, 5e-4, 1e-4, 5e-5, 1e-5])\n# tuner = kt.Hyperband(\n#                      MyHypermodel(include_top=False, input_shape=(256, 256, 3), input_tensor=None, classes=n_unique_identities),\n#                      objective='val_accuracy',\n# #                      hyperparameters=hp,\n#                      max_epochs=50,\n#                      factor=3,\n#                      directory='my_dir',\n#                      project_name='intro_to_kt5',\n#                      overwrite=True)\n# hypermodel = kt.applications.HyperResNet(\n#     include_top=False, input_shape=(256, 256, 3), input_tensor=None, classes=None, **kwargs\n# )","metadata":{"execution":{"iopub.status.busy":"2024-03-19T04:33:46.671906Z","iopub.execute_input":"2024-03-19T04:33:46.672161Z","iopub.status.idle":"2024-03-19T04:33:46.687813Z","shell.execute_reply.started":"2024-03-19T04:33:46.672139Z","shell.execute_reply":"2024-03-19T04:33:46.687016Z"},"trusted":true},"execution_count":null,"outputs":[]},{"cell_type":"code","source":"# stop_early = tf.keras.callbacks.EarlyStopping(monitor='val_loss', patience=5)","metadata":{"execution":{"iopub.status.busy":"2024-03-19T04:33:46.688726Z","iopub.execute_input":"2024-03-19T04:33:46.688973Z","iopub.status.idle":"2024-03-19T04:33:46.696873Z","shell.execute_reply.started":"2024-03-19T04:33:46.688952Z","shell.execute_reply":"2024-03-19T04:33:46.695983Z"},"trusted":true},"execution_count":null,"outputs":[]},{"cell_type":"code","source":"# tuner.search(train_data, epochs=100, validation_data=val_data, callbacks=[stop_early])\n\n# Get the optimal hyperparameters\n# best_hps=tuner.get_best_hyperparameters(num_trials=1)[0]","metadata":{"execution":{"iopub.status.busy":"2024-03-19T04:33:46.697978Z","iopub.execute_input":"2024-03-19T04:33:46.698390Z","iopub.status.idle":"2024-03-19T04:33:46.705926Z","shell.execute_reply.started":"2024-03-19T04:33:46.698358Z","shell.execute_reply":"2024-03-19T04:33:46.705141Z"},"trusted":true},"execution_count":null,"outputs":[]},{"cell_type":"code","source":"# print(f\"\"\"\n# The hyperparameter search is complete. The optimal learning rate for the optimizer\n# is {best_hps.get('learning_rate')}.\n# \"\"\")","metadata":{"execution":{"iopub.status.busy":"2024-03-19T04:33:46.706920Z","iopub.execute_input":"2024-03-19T04:33:46.707212Z","iopub.status.idle":"2024-03-19T04:33:46.715457Z","shell.execute_reply.started":"2024-03-19T04:33:46.707190Z","shell.execute_reply":"2024-03-19T04:33:46.714682Z"},"trusted":true},"execution_count":null,"outputs":[]},{"cell_type":"code","source":"# # Set the number of neurons in the dense layers\n# neurons = 1024\n\n# Define the AlexNet model\n# model = Sequential()\n# model.add(layers.experimental.preprocessing.Resizing(227, 227, interpolation=\"bilinear\", input_shape=final_X.shape[1:]))\n# model.add(layers.Conv2D(96, 11, strides=4, padding='same', input_shape=(227,227,3)))\n# model.add(layers.Lambda(tf.nn.local_response_normalization))\n# model.add(layers.Activation('relu'))\n# model.add(layers.MaxPooling2D(3, strides=2))\n# model.add(layers.Conv2D(256, 5, strides=2, padding='same'))\n# model.add(layers.Lambda(tf.nn.local_response_normalization))\n# model.add(layers.Activation('relu'))\n# model.add(layers.MaxPooling2D(3, strides=2))\n# model.add(layers.Conv2D(384, 3, strides=1, padding='same'))\n# model.add(layers.Activation('relu'))\n# model.add(layers.Conv2D(384, 3, strides=1, padding='same'))\n# model.add(layers.Activation('relu'))\n# model.add(layers.Conv2D(256, 3, strides=1, padding='same'))\n# model.add(layers.Activation('relu'))\n# model.add(layers.MaxPooling2D(3, strides=2))\n# model.add(layers.Flatten())\n# model.add(layers.Dense(4096, activation='relu'))\n# model.add(layers.Dropout(0.5))\n# model.add(layers.Dense(4096, activation='relu'))\n# model.add(layers.Dropout(0.5))\n# model.add(layers.Dense(n_unique_identities, activation='softmax'))\n\nbase_model_mobilenet = MobileNet(weights='imagenet', include_top=False, input_shape=(224, 224, 3))\nbase_model_mobilenet.trainable = False\n# print(base_model_mobilenet.summary())\n# Create a function to add a new top layer (classifier) to the base models\ndef add_new_top_layer(base_model, num_classes):\n    x = base_model.output\n#     x = Flatten()(x)\n    x = GlobalAveragePooling2D()(x)\n    x = Dense(1024, activation='relu')(x)\n    x = Dropout(0.5)(x)\n    predictions = Dense(num_classes, activation='softmax')(x)\n    model = Model(inputs=base_model.input, outputs=predictions)\n    return model\n\n# Add new top layers\n# model_resnet50 = add_new_top_layer(base_model_resnet50, num_classes)\nmodel_mobilenet = add_new_top_layer(base_model_mobilenet, n_unique_identities)\n# print(model_mobilenet.summary())\n\n# # model = Sequential()\n# # model.add(Conv2D(96, 11, strides=4, padding='same', input_shape=(227,227,3)))\n# # model.add(Lambda(tf.nn.local_response_normalization))\n# # model.add(Activation('relu'))\n# # model.add(MaxPooling2D(pool_size=3, strides=2))\n\n# # model.add(Conv2D(256, 5, strides=4, padding='same'))\n# # # model.add(Lambda(tf.nn.local_response_normalization))\n# # model.add(Activation('relu'))\n# # model.add(MaxPooling2D(pool_size=3, strides=2))\n# # # Add more layers as per the AlexNet architecture...\n# # model.add(Flatten())\n# # model.add(Dense(neurons, activation='relu'))\n# # model.add(Dense(neurons, activation='relu'))\n# # model.add(Dense(19, activation='softmax'))  # num_classes should be the number of classes in dataset\n\n# # # Compile the model\n# # model.compile(optimizer='adam', loss=losses.categorical_crossentropy, metrics=['accuracy'])\n# # rescale = tf.keras.layers.Rescaling(1./127.5, offset=-1)\n# # base_model = tf.keras.applications.MobileNetV2(input_shape=(160,160,3),\n# #                                                include_top=False,\n# #                                                weights='imagenet')\n# # base_model.trainable = False\n# # # global_average_layer = tf.keras.layers.GlobalAveragePooling2D()\n# # prediction_layer = tf.keras.layers.Dense(19, activation='softmax')\n\n# # inputs = tf.keras.Input(shape=(160, 160, 3))\n# # # x = data_augmentation(inputs)\n# # x = rescale(inputs)\n# # x = base_model(x, training=False)\n# # # x = global_average_layer(x)\n# # x = tf.keras.layers.Flatten()(x)\n# # x = tf.keras.layers.Dropout(0.5)(x)\n# # outputs = prediction_layer(x)\n# # model = tf.keras.Model(inputs, outputs)\n\nbase_learning_rate = 0.00005\nmodel_mobilenet.compile(optimizer=tf.keras.optimizers.Adam(learning_rate=base_learning_rate),\n              loss=tf.keras.losses.categorical_crossentropy,\n              metrics=['accuracy'])","metadata":{"execution":{"iopub.status.busy":"2024-03-19T04:33:46.716959Z","iopub.execute_input":"2024-03-19T04:33:46.717355Z","iopub.status.idle":"2024-03-19T04:33:47.742588Z","shell.execute_reply.started":"2024-03-19T04:33:46.717329Z","shell.execute_reply":"2024-03-19T04:33:47.741582Z"},"trusted":true},"execution_count":null,"outputs":[]},{"cell_type":"code","source":"# # Train the model\nmodel_mobilenet.fit(train_data, epochs=25, validation_data=val_data, callbacks=keras.callbacks.EarlyStopping(patience=5))","metadata":{"execution":{"iopub.status.busy":"2024-03-19T04:33:47.743879Z","iopub.execute_input":"2024-03-19T04:33:47.744175Z","iopub.status.idle":"2024-03-19T04:37:53.503773Z","shell.execute_reply.started":"2024-03-19T04:33:47.744151Z","shell.execute_reply":"2024-03-19T04:37:53.502695Z"},"trusted":true},"execution_count":null,"outputs":[]},{"cell_type":"markdown","source":"# Validate for test set","metadata":{}},{"cell_type":"code","source":"# Initialize the label encoder\n# le = LabelEncoder()\n\n# Fit the label encoder and transform the labels\n# Y_int_test = le.fit_transform(y_test)\n# Y_int_test = le.inverse_transform(y_test)\nY_int_test = le.transform(y_test)\nY_one_hot_test = to_categorical(Y_int_test, num_classes=n_unique_identities)","metadata":{"execution":{"iopub.status.busy":"2024-03-19T04:37:53.505063Z","iopub.execute_input":"2024-03-19T04:37:53.505387Z","iopub.status.idle":"2024-03-19T04:37:53.511382Z","shell.execute_reply.started":"2024-03-19T04:37:53.505360Z","shell.execute_reply":"2024-03-19T04:37:53.510303Z"},"trusted":true},"execution_count":null,"outputs":[]},{"cell_type":"code","source":"from sklearn.metrics import classification_report\nimport numpy as np\nfrom keras.models import load_model\nimport os\n\ntest_data = tf.data.Dataset.from_tensor_slices((cropped_face_x_test,))\ntest_data = test_data.map(lambda x: (normalize_image(x))).batch(32)\n\n# models = {}\n# for model_file in os.listdir(\"/kaggle/input/test-models/model\"):\n#     if model_file.endswith(\".h5\"):\n#         models[model_file] = load_model(\"/kaggle/input/test-models/model/\" + model_file)\n\n# for model in models:\nprint(f\"Model: {model_mobilenet}\")\nval_predictions = model_mobilenet.predict(test_data)\n\n# Convert predictions classes to one hot vectors \nval_predictions_classes = np.argmax(val_predictions, axis = 1) \n# Convert validation observations to one hot vectors\nval_true = np.argmax(Y_one_hot_test, axis = 1)\n\n# Generate the classification report\nreport = classification_report(val_true, val_predictions_classes)\nprint(report)\n","metadata":{"execution":{"iopub.status.busy":"2024-03-19T04:37:53.512840Z","iopub.execute_input":"2024-03-19T04:37:53.513128Z","iopub.status.idle":"2024-03-19T04:38:59.739076Z","shell.execute_reply.started":"2024-03-19T04:37:53.513103Z","shell.execute_reply":"2024-03-19T04:38:59.738087Z"},"trusted":true},"execution_count":null,"outputs":[]},{"cell_type":"code","source":"from sklearn.metrics import confusion_matrix, ConfusionMatrixDisplay\n\nc_mat = confusion_matrix(val_true, val_predictions_classes)\ndisp = ConfusionMatrixDisplay(c_mat)\ndisp.plot()\n\nplt.show()\n","metadata":{"execution":{"iopub.status.busy":"2024-03-19T04:38:59.745287Z","iopub.execute_input":"2024-03-19T04:38:59.745609Z","iopub.status.idle":"2024-03-19T04:39:06.845022Z","shell.execute_reply.started":"2024-03-19T04:38:59.745582Z","shell.execute_reply":"2024-03-19T04:39:06.844027Z"},"trusted":true},"execution_count":null,"outputs":[]},{"cell_type":"code","source":"model_mobilenet.save('/kaggle/working/base_model-mobilenet-62I-10E-00005LR-bitcrushed-35-40.h5')","metadata":{"execution":{"iopub.status.busy":"2024-03-19T04:42:23.098072Z","iopub.execute_input":"2024-03-19T04:42:23.098535Z","iopub.status.idle":"2024-03-19T04:42:23.302249Z","shell.execute_reply.started":"2024-03-19T04:42:23.098498Z","shell.execute_reply":"2024-03-19T04:42:23.301236Z"},"trusted":true},"execution_count":null,"outputs":[]},{"cell_type":"code","source":"!ls /kaggle/working","metadata":{"execution":{"iopub.status.busy":"2024-03-19T04:39:07.100993Z","iopub.execute_input":"2024-03-19T04:39:07.101332Z","iopub.status.idle":"2024-03-19T04:39:08.473909Z","shell.execute_reply.started":"2024-03-19T04:39:07.101307Z","shell.execute_reply":"2024-03-19T04:39:08.472707Z"},"trusted":true},"execution_count":null,"outputs":[]},{"cell_type":"code","source":"# Print the class names\nprint(\"Class names:\", le.classes_)\n","metadata":{"execution":{"iopub.status.busy":"2024-03-19T04:39:08.475430Z","iopub.execute_input":"2024-03-19T04:39:08.475738Z","iopub.status.idle":"2024-03-19T04:39:08.489300Z","shell.execute_reply.started":"2024-03-19T04:39:08.475714Z","shell.execute_reply":"2024-03-19T04:39:08.488096Z"},"trusted":true},"execution_count":null,"outputs":[]},{"cell_type":"code","source":"\n# print(\"Shape of labels:\", Y_int.shape)\n","metadata":{"execution":{"iopub.status.busy":"2024-03-19T04:39:08.490747Z","iopub.execute_input":"2024-03-19T04:39:08.491383Z","iopub.status.idle":"2024-03-19T04:39:08.496990Z","shell.execute_reply.started":"2024-03-19T04:39:08.491355Z","shell.execute_reply":"2024-03-19T04:39:08.496008Z"},"trusted":true},"execution_count":null,"outputs":[]},{"cell_type":"code","source":"# # Convert lists to Numpy arrays\n# final_X = np.array(cropped_face_X)\n# final_x_test = np.array(cropped_face_x_test)\n\n# print(\"Shape of training data:\", final_X.shape)\n# print(\"Shape of test data:\", final_x_test.shape)\n","metadata":{"execution":{"iopub.status.busy":"2024-03-19T04:39:08.498015Z","iopub.execute_input":"2024-03-19T04:39:08.498296Z","iopub.status.idle":"2024-03-19T04:39:08.507698Z","shell.execute_reply.started":"2024-03-19T04:39:08.498273Z","shell.execute_reply":"2024-03-19T04:39:08.506764Z"},"trusted":true},"execution_count":null,"outputs":[]},{"cell_type":"code","source":"# for i in range(n_unique_identities):\n#     print(f\"{i}: {le.inverse_transform(i)}\")\nprint(le.inverse_transform([i for i in range(n_unique_identities)]))","metadata":{"execution":{"iopub.status.busy":"2024-03-19T04:39:08.508749Z","iopub.execute_input":"2024-03-19T04:39:08.509008Z","iopub.status.idle":"2024-03-19T04:39:08.525268Z","shell.execute_reply.started":"2024-03-19T04:39:08.508986Z","shell.execute_reply":"2024-03-19T04:39:08.524372Z"},"trusted":true},"execution_count":null,"outputs":[]},{"cell_type":"code","source":"!pip show keras","metadata":{"execution":{"iopub.status.busy":"2024-03-19T04:39:08.526425Z","iopub.execute_input":"2024-03-19T04:39:08.526720Z","iopub.status.idle":"2024-03-19T04:39:20.828230Z","shell.execute_reply.started":"2024-03-19T04:39:08.526697Z","shell.execute_reply":"2024-03-19T04:39:20.826781Z"},"trusted":true},"execution_count":null,"outputs":[]},{"cell_type":"code","source":"!mv /kaggle/working/Dataset/Raw/data.npz /kaggle/working/data.npz","metadata":{},"execution_count":null,"outputs":[]},{"cell_type":"code","source":"!tar -zcvf export.tar.gz data.npz base_model-mobilenet-62I-10E-00005LR-bitcrushed-35-40.h5","metadata":{},"execution_count":null,"outputs":[]},{"cell_type":"code","source":"!rm -rf /kaggle/working/Dataset base_model-mobilenet-62I-10E-00005LR-bitcrushed-35-40.h5","metadata":{},"execution_count":null,"outputs":[]}]}