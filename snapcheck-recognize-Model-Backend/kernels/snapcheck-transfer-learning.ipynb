{"metadata":{"kaggle":{"accelerator":"gpu","dataSources":[{"sourceId":7745555,"sourceType":"datasetVersion","datasetId":4527786},{"sourceId":7891581,"sourceType":"datasetVersion","datasetId":4531911},{"sourceId":7907580,"sourceType":"datasetVersion","datasetId":4527738}],"dockerImageVersionId":30664,"isInternetEnabled":true,"language":"python","sourceType":"notebook","isGpuEnabled":true},"kernelspec":{"display_name":"Python 3","language":"python","name":"python3"},"language_info":{"codemirror_mode":{"name":"ipython","version":3},"file_extension":".py","mimetype":"text/x-python","name":"python","nbconvert_exporter":"python","pygments_lexer":"ipython3","version":"3.10.13"}},"nbformat_minor":4,"nbformat":4,"cells":[{"cell_type":"code","source":"!cp -r /kaggle/input/mates-only-v3 /kaggle/working/mates-only-v3\n!cp -r /kaggle/input/transfer-learning-base /kaggle/working/transfer-learning-base\n!cp -r /kaggle/input/new-transfer-data /kaggle/working/new-transfer-data","metadata":{"_cell_guid":"b1076dfc-b9ad-4769-8c92-a6c4dae69d19","_uuid":"8f2839f25d086af736a60e9eeb907d3b93b6e0e5","execution":{"iopub.status.busy":"2024-03-20T05:12:16.913930Z","iopub.execute_input":"2024-03-20T05:12:16.914351Z","iopub.status.idle":"2024-03-20T05:12:23.635938Z","shell.execute_reply.started":"2024-03-20T05:12:16.914309Z","shell.execute_reply":"2024-03-20T05:12:23.634756Z"},"trusted":true},"execution_count":null,"outputs":[]},{"cell_type":"code","source":"%pip install keras==2.15.0","metadata":{"execution":{"iopub.status.busy":"2024-03-20T05:12:23.638218Z","iopub.execute_input":"2024-03-20T05:12:23.638542Z","iopub.status.idle":"2024-03-20T05:12:39.763162Z","shell.execute_reply.started":"2024-03-20T05:12:23.638511Z","shell.execute_reply":"2024-03-20T05:12:39.761948Z"},"trusted":true},"execution_count":null,"outputs":[]},{"cell_type":"code","source":"SHUFFLE_NUMBER = 42","metadata":{"execution":{"iopub.status.busy":"2024-03-20T05:12:39.764914Z","iopub.execute_input":"2024-03-20T05:12:39.765299Z","iopub.status.idle":"2024-03-20T05:12:39.770577Z","shell.execute_reply.started":"2024-03-20T05:12:39.765252Z","shell.execute_reply":"2024-03-20T05:12:39.769314Z"},"trusted":true},"execution_count":null,"outputs":[]},{"cell_type":"code","source":"import math\nimport os\nimport random\nimport re\nimport shutil\nimport sys\nimport time\nfrom collections import Counter\nfrom pathlib import Path\nfrom typing import Any, Callable\n\nimport albumentations as A\nimport cv2\nimport imgaug\nimport keras\nimport matplotlib.image as mpimg\nimport matplotlib.pyplot as plt\nimport numpy as np\nimport tensorflow as tf\nimport tqdm\nfrom keras import backend as K\nfrom keras import layers, losses\nfrom keras.applications import MobileNet\nfrom keras.layers import (Activation, Conv2D, Dense, Dropout, GlobalAveragePooling2D, Flatten, Lambda,\n                          MaxPooling2D)\nfrom keras.models import Sequential, Model\nfrom keras.utils import to_categorical\nfrom PIL import Image\nfrom rich import print\nfrom sklearn.calibration import LabelEncoder\nfrom sklearn.model_selection import train_test_split\n","metadata":{"execution":{"iopub.status.busy":"2024-03-20T05:12:39.773383Z","iopub.execute_input":"2024-03-20T05:12:39.773689Z","iopub.status.idle":"2024-03-20T05:12:53.628198Z","shell.execute_reply.started":"2024-03-20T05:12:39.773663Z","shell.execute_reply":"2024-03-20T05:12:53.627314Z"},"trusted":true},"execution_count":null,"outputs":[]},{"cell_type":"code","source":"def identity(x):\n    return x\n\ndef swap(t):\n    return (t[1],t[0])\n\ndef count_fds(path):\n    items = 0\n    for _ in Path(path).iterdir():\n        items += 1\n    return items\n\ndef count_dirs(path):\n    items = 0\n    for p in Path(path).iterdir():\n        if p.is_dir():\n            items += 1\n    return items","metadata":{"execution":{"iopub.status.busy":"2024-03-20T05:12:53.629387Z","iopub.execute_input":"2024-03-20T05:12:53.629938Z","iopub.status.idle":"2024-03-20T05:12:53.638433Z","shell.execute_reply.started":"2024-03-20T05:12:53.629910Z","shell.execute_reply":"2024-03-20T05:12:53.635429Z"},"trusted":true},"execution_count":null,"outputs":[]},{"cell_type":"code","source":"random.seed(SHUFFLE_NUMBER)\nimgaug.seed(SHUFFLE_NUMBER)","metadata":{"execution":{"iopub.status.busy":"2024-03-20T05:12:53.639543Z","iopub.execute_input":"2024-03-20T05:12:53.642124Z","iopub.status.idle":"2024-03-20T05:12:53.747238Z","shell.execute_reply.started":"2024-03-20T05:12:53.642086Z","shell.execute_reply":"2024-03-20T05:12:53.746072Z"},"trusted":true},"execution_count":null,"outputs":[]},{"cell_type":"code","source":"default_transform = A.Compose(\n    [\n#         A.RandomCrop(width=200, height=200),\n        A.RandomCropFromBorders (crop_left=0.1, crop_right=0.1, crop_top=0.1, crop_bottom=0.1),\n        A.HorizontalFlip(p=0.5),\n        # A.RandomScale(scale_limit=(-0.5, 2.0), p=0.5),\n        A.ShiftScaleRotate(p=0.5, shift_limit=0.1, scale_limit=0.2, rotate_limit=15),\n        A.RandomBrightnessContrast(p=0.2),\n        A.Blur(blur_limit=3, p=0.2),\n        A.Downscale(scale_min=0.70, scale_max=0.80, p=1)\n    ]\n)\n\n\n\ndef augment_data(\n    img: np.ndarray,\n    augmentation_count: int = 10,\n    augmentation_pipeline=None,\n    desired_shape: tuple[int, int] = (250, 250),\n) -> list[np.ndarray]:\n    images = []\n    if augmentation_pipeline is None:\n        augmentation_pipeline = default_transform\n    for _ in range(augmentation_count):\n        aug_image = augmentation_pipeline(image=img)[\"image\"]\n        aug_image = Image.fromarray(aug_image).resize(swap(desired_shape))\n        aug_image = np.array(aug_image)\n        images.append(aug_image)\n    return images\n","metadata":{"execution":{"iopub.status.busy":"2024-03-20T05:43:59.085434Z","iopub.execute_input":"2024-03-20T05:43:59.086234Z","iopub.status.idle":"2024-03-20T05:43:59.096055Z","shell.execute_reply.started":"2024-03-20T05:43:59.086201Z","shell.execute_reply":"2024-03-20T05:43:59.095037Z"},"trusted":true},"execution_count":null,"outputs":[]},{"cell_type":"code","source":"class LazyData:\n    face_cascade = cv2.CascadeClassifier(cv2.data.haarcascades + 'haarcascade_frontalface_default.xml')\n    \n    def __init__(\n        self,\n        filename: str,\n        load_strategy: str | Callable[[str | bytes], Any] | None = None,\n        *args,\n        **kwargs,\n    ):\n        self._filename = filename\n        self._data = None\n        self._load_strategy = load_strategy\n        self._args = args\n        self._kwargs = kwargs\n\n    def __call__(self):\n        if self._data is None:\n            self._build_data()\n        return self._data\n\n    def __load_strategy_image(self, buf) -> np.ndarray[np.uint8]:\n        img = mpimg.imread(buf, format=\"jpg\")\n        if self._kwargs.get(\"desired_shape\") is not None:\n            pilimg = Image.fromarray(img).resize(self._kwargs.get(\"desired_shape\"), Image.ANTIALIAS)\n            img = np.array(pilimg)\n        return img\n    \n    def __load_strategy_image_face(self, buf) -> np.ndarray[np.uint8]:\n        img = mpimg.imread(buf, format=\"jpg\")\n#         print(\"__load_strategy_image_face\")\n        if self._kwargs.get(\"desired_shape\") is not None:\n            desired_shape = self._kwargs.get(\"desired_shape\")\n            if desired_shape[0] > img.shape[0] or desired_shape[1] > img.shape[1]:\n#                 print(\"Failure point 1: Desired Shape can't be fit inside image\")\n#                 print(f\"{desired_shape[0] = }, {desired_shape[1] = }\")\n#                 print(f\"{img.shape[0] = }, {img.shape[1] = }\")\n                return img\n            \n            image = img.copy()\n            faces = LazyData.face_cascade.detectMultiScale(image, scaleFactor=1.1, minNeighbors=5, minSize=(30, 30))\n            if len(faces) > 0:\n                x, y, w, h = faces[0]\n            else:\n                x, y, w, h = 0, 0, img.shape[1], img.shape[0]\n            \n            cx, cy = (x + x + w)//2, (y + y + h)//2\n            nw, nh = desired_shape[1], desired_shape[0]\n            exw, exh = w, h\n            \n            if nw < w:\n                exw = nw\n            if nh < h:\n                exh = nh\n            if nw > w:\n                lb = cx - nw//2\n                rb = cx + nw//2\n                if lb < 0 and rb > img.shape[1]:\n                    raise Exception(\"AbsurdError: Desired shape greater than image\")\n                elif lb < 0:\n                    cx += -lb\n                elif rb > img.shape[1]:\n                    cx -= (rb - img.shape[1])\n            if nh > h:\n                ub = cy - nh//2\n                db = cy + nh//2\n                if ub < 0 and db > img.shape[0]:\n                    raise Exception(\"AbsurdError: Desired shape greater than image\")\n                elif ub < 0:\n                    cy += -ub\n                elif db > img.shape[0]:\n                    cy -= (db - img.shape[0])\n            \n            new_img = img[(cy-nh//2):(cy+nh//2), (cx-nw//2):(cx+nw//2)]\n#             print(new_img.shape)\n            # possible off by ones correction\n#             print(swap(desired_shape))\n            pilimg = Image.fromarray(img).resize(swap(desired_shape), Image.ANTIALIAS)\n            img = np.array(pilimg)\n#         print(img.shape)\n        return img\n            \n    def _build_data(self):\n        with open(self._filename, \"rb\") as f:\n            if self._load_strategy is None:\n                self._data = f.read()\n            elif self._load_strategy == \"image\":\n                self._data = self.__load_strategy_image(self._filename)\n            elif self._load_strategy == \"image_face\":\n                self._data = self.__load_strategy_image_face(self._filename)\n            else:\n                buf = f.read()\n                self._data = self._load_strategy(buf)","metadata":{"execution":{"iopub.status.busy":"2024-03-20T05:43:59.392302Z","iopub.execute_input":"2024-03-20T05:43:59.392735Z","iopub.status.idle":"2024-03-20T05:43:59.438543Z","shell.execute_reply.started":"2024-03-20T05:43:59.392695Z","shell.execute_reply":"2024-03-20T05:43:59.437746Z"},"trusted":true},"execution_count":null,"outputs":[]},{"cell_type":"code","source":"def dataset(\n    path: str,\n    min_faces: int | None = 20,\n    max_faces: int | None = None,\n    hard_limit: bool = False,\n    shuffle: bool = True,\n    random_state: int | None = None,\n    verbose: bool | None = True,\n    desired_shape: tuple[int,int] = (250,250)\n):\n    if random_state is not None:\n        np.random.seed(random_state)\n\n    excluded_dirs = []\n    capped_dirs = []\n    capped_counts = {}\n    for direc in os.listdir(path):\n        if os.path.isdir(os.path.join(path, direc)):\n            if min_faces is not None:\n                if len(os.listdir(os.path.join(path, direc))) < min_faces:\n                    excluded_dirs.append(direc)\n            if max_faces is not None:\n                if len(os.listdir(os.path.join(path, direc))) > max_faces:\n                    if hard_limit:\n                        excluded_dirs.append(direc)\n                    else:\n                        capped_dirs.append(direc)\n\n    ds = []\n    tracker = tqdm.tqdm if verbose else identity\n    pattern = re.compile(r\"(.*)_(?:\\d+)\\.jpg\")\n\n    for root, dirs, files in tracker(os.walk(path)):\n        for file in files:\n            if file.endswith(\".jpg\"):\n                match = pattern.match(file)\n                if match:\n                    target = match.group(1)\n\n                    if target in excluded_dirs:\n                        continue\n\n                    if max_faces is not None:\n                        if target in capped_dirs:\n                            if target not in capped_counts:\n                                capped_counts[target] = 0\n                            capped_counts[target] += 1\n                            if capped_counts[target] > max_faces:\n                                continue\n\n                    ds.append(\n                        [\n                            LazyData(\n                                os.path.abspath(os.path.join(root, file)),\n                                load_strategy=\"image_face\",\n                                desired_shape=desired_shape\n                            ),\n                            target,\n                        ]\n                    )\n\n    if shuffle:\n        np.random.shuffle(ds)\n\n    return np.array(ds)\n\n\ndef fetch_lfw_people(\n    path_to_dataset: str = \"Dataset/Raw\",\n    min_faces: int | None = 20,\n    max_faces: int | None = None,\n    hard_limit: bool = False,\n    shuffle: bool = True,\n    random_state: int | None = None,\n    verbose: bool = True,\n    desired_shape: tuple[int,int] = (250, 250)\n):\n    dst = dataset(\n        path_to_dataset,\n        min_faces=min_faces,\n        max_faces=max_faces,\n        hard_limit=hard_limit,\n        shuffle=shuffle,\n        random_state=random_state,\n        verbose=verbose,\n        desired_shape=desired_shape,\n    )\n    X = dst[:, 0]\n    Y = dst[:, 1]\n    return X, Y\n","metadata":{"execution":{"iopub.status.busy":"2024-03-20T05:43:59.721774Z","iopub.execute_input":"2024-03-20T05:43:59.722152Z","iopub.status.idle":"2024-03-20T05:43:59.739002Z","shell.execute_reply.started":"2024-03-20T05:43:59.722104Z","shell.execute_reply":"2024-03-20T05:43:59.737824Z"},"trusted":true},"execution_count":null,"outputs":[]},{"cell_type":"code","source":"def visualize_image(axes_array, images_array, labels_array, figure):\n    axes_array = axes_array.flatten()\n\n    # assert len(axes_array) == len(images_array) == len(labels_array)\n    assert len(axes_array) <= len(images_array)\n    assert len(axes_array) <= len(labels_array)\n\n    for i, ax in enumerate(axes_array):\n        img = ax.imshow(images_array[i], cmap=\"gray\")\n        figure.colorbar(img, ax=ax)\n        ax.set_title(labels_array[i])\n        ax.axis(\"off\")\n","metadata":{"execution":{"iopub.status.busy":"2024-03-20T05:43:59.996301Z","iopub.execute_input":"2024-03-20T05:43:59.996712Z","iopub.status.idle":"2024-03-20T05:44:00.004835Z","shell.execute_reply.started":"2024-03-20T05:43:59.996680Z","shell.execute_reply":"2024-03-20T05:44:00.003815Z"},"trusted":true},"execution_count":null,"outputs":[]},{"cell_type":"code","source":"","metadata":{},"execution_count":null,"outputs":[]},{"cell_type":"code","source":"\n\n# TODO: Documentation\n\n\ndef dump_test_files(x_test, y_test, path_prefix: str, verbose=True):\n    # clear out the directory\n    if os.path.exists(path_prefix):\n        shutil.rmtree(path_prefix)\n\n    if os.path.exists(path_prefix + \".zip\"):\n        os.remove(path_prefix + \".zip\")\n\n    os.makedirs(path_prefix)\n\n    freq_table = {}\n    for i, x in enumerate(x_test):\n        target = y_test[i]\n        if target not in freq_table:\n            freq_table[target] = 0\n            os.makedirs(os.path.join(path_prefix, str(target)))\n        freq_table[target] += 1\n\n        # write image as jpeg\n        Image.fromarray(x).save(\n            os.path.join(\n                path_prefix, str(target), f\"{target}_{freq_table[target]:04}.jpg\"\n            )\n        )\n\n    shutil.make_archive(path_prefix, \"zip\", path_prefix)\n    if verbose:\n        print(\"[bold green]Test files dumped successfully[/bold green]\")\n\n    shutil.rmtree(os.path.join(path_prefix))\n\n\ndef export_dataset_objects(\n    path_to_dataset: str = \"Dataset/Raw\",\n    min_faces: int | None = 20,\n    max_faces: int | None = None,\n    hard_limit: bool = False,\n    shuffle=True,\n    random_state=None,\n    test_size=0.2,\n    verbose=True,\n    augment=True,\n    desired_shape: tuple[int, int] = (250, 250),\n    augmentation_count: int = 10,\n    augmentation_upto: int | None = None,\n    augmentation_pipeline=None,\n    experimental_export: bool = True,\n    export: bool = True,\n):\n    X, Y = fetch_lfw_people(\n        path_to_dataset=path_to_dataset,\n        min_faces=min_faces,\n        max_faces=max_faces,\n        hard_limit=hard_limit,\n        shuffle=shuffle,\n        random_state=random_state,\n        verbose=verbose,\n        desired_shape=desired_shape,\n    )\n\n    log = print if verbose else identity\n\n    log(\"[bold green]Dataset loaded successfully[/bold green]\")\n\n    export_path = os.path.dirname(path_to_dataset)\n\n    tracker = tqdm.tqdm if verbose else identity\n\n    # print(sys.getsizeof(X[0]))\n    # exit(1)\n\n    __x = []\n    for x in tracker(X):\n        __x.append(x())\n    # # exit(1)\n\n    __x = np.array(__x, copy=False)\n    log(\"[bold green]Binary data loaded successfully[/bold green]\")\n    # __x = np.zeros((X.shape[0], 250, 250, 3), dtype=np.uint8)\n    # print(__x.shape)\n    # for i, x in tracker(enumerate(X)):\n    #     __x[i] = x()\n\n    x_train, x_test, y_train, y_test = train_test_split(\n        __x,\n        Y,\n        test_size=test_size,\n        random_state=random_state,\n        stratify=Y,\n    )\n\n    log(\"[bold green]Dataset split successfully[/bold green]\")\n\n    if augment:\n        if augmentation_upto is None:\n            xy = []\n            for i, x in tracker(enumerate(x_train)):\n                aug_data = augment_data(\n                    x,\n                    desired_shape=desired_shape,\n                    augmentation_count=augmentation_count,\n                    augmentation_pipeline=augmentation_pipeline,\n                )\n\n                for data in aug_data:\n#                     data = Image.fromarray(data).convert(\"L\")\n#                     data = np.array(data, copy=False)\n                    xy.append([data, y_train[i]])\n                # print(xy)\n                # fig, axes = plt.subplots(2, 5, figsize=(20, 10))\n                # axes = axes.flatten()\n\n                # for img, ax in zip(aug_data, axes):\n                #     ax.imshow(img)\n                #     ax.axis(\"off\")\n                # plt.tight_layout()\n                # plt.show()\n\n                # exit(1)\n            log(\"[bold green]Augmentation done successfully[/bold green]\")\n            xy_data = np.array(xy, dtype=object, copy=False)\n            log(\"[bold green]Augmented data converted to numpy array[/bold green]\")\n            if shuffle:\n                np.random.shuffle(xy_data)\n                log(\"[bold green]Augmented data shuffled successfully[/bold green]\")\n\n            x_train_data = xy_data[:, 0]\n            log(\"[bold green]x_train_data split successfully[/bold green]\")\n            y_train_data = xy_data[:, 1]\n            log(\"[bold green]y_train_data split successfully[/bold green]\")\n#             x_train_data = x_train_data / 255\n            log(\"[bold green]x_train_data normalized successfully[/bold green]\")\n#             x_test = x_test / 255\n            log(\"[bold green]x_test normalized successfully[/bold green]\")\n            if export:\n                if not experimental_export:\n                    x_train_data.dump(os.path.join(export_path, \"x_train.npy\"))\n                    y_train_data.dump(os.path.join(export_path, \"y_train.npy\"))\n                    x_test.dump(os.path.join(export_path, \"x_test.npy\"))\n                    y_test.dump(os.path.join(export_path, \"y_test.npy\"))\n                else:\n                    np.savez_compressed(\n                        os.path.join(export_path, \"data.npz\"),\n                        x_train=x_train_data,\n                        y_train=y_train_data,\n                        x_test=x_test,\n                        y_test=y_test,\n                    )\n                    log(\"[bold green]Dataset exported successfully[/bold green]\")\n\n            # og_data = np.array(__x)\n            # og_data.dump(\"Dataset/x_og.npy\")\n            # y_data.dump(\"Dataset/y.npy\")\n        else:\n            xy = []\n            idents = {}\n            for i, y in enumerate(y_train):\n                if y in idents:\n                    idents[y].append(i)\n                else:\n                    idents[y] = [i]\n            log(\"[bold green]Identified classes successfully[/bold green]\")\n\n            if augmentation_upto == 0:\n                # augment upto max_faces\n                if max_faces is None:\n                    raise Exception(\"max_faces must be int if augmentation_upto is 0\")\n\n                for y in idents:\n                    augmentation_len = max_faces - len(idents[y])\n                    for _k in range(augmentation_len):\n                        # choose random image\n                        random_image = np.random.choice(idents[y])\n                        # augment it\n                        aug_data = augment_data(\n                            x_train[random_image],\n                            desired_shape=desired_shape,\n                            augmentation_count=1,\n                            augmentation_pipeline=augmentation_pipeline,\n                        )\n                        aug_image = aug_data[0]\n#                         aug_image = Image.fromarray(aug_image).convert(\"L\")\n#                         aug_image = np.array(aug_image, copy=False)\n                        # add it to the dataset\n                        xy.append([aug_image, y])\n                    log(\n                        \"[bold green]Augmented upto max_faces successfully[/bold green]\"\n                    )\n            elif augmentation_upto > 0:\n                # augment upto augmentation_upto\n                for y in idents:\n                    faces = len(idents[y])\n                    if augmentation_upto > faces:\n                        augmentation_len = augmentation_upto - len(idents[y])\n                        for _k in range(augmentation_len):\n                            # choose random image\n                            random_image = np.random.choice(idents[y])\n                            # augment it\n                            aug_data = augment_data(\n                                x_train[random_image],\n                                desired_shape=desired_shape,\n                                augmentation_count=1,\n                                augmentation_pipeline=augmentation_pipeline,\n                            )\n                            aug_image = aug_data[0]\n#                             aug_image = Image.fromarray(aug_image).convert(\"L\")\n#                             aug_image = np.array(aug_image, copy=False)\n                            # add it to the dataset\n                            xy.append([aug_image, y])\n                log(\n                    \"[bold green]Augmented upto augmentation_upto successfully[/bold green]\"\n                )\n            else:\n                raise Exception(\"augmentation_upto must be bool or int\")\n\n            # add the original image with the label\n            for i, x in tracker(enumerate(x_train)):\n                cv_image = x\n#                 cv_image = Image.fromarray(cv_image).convert(\"L\")\n#                 cv_image = np.array(cv_image, copy=False)\n                xy.append([cv_image, y_train[i]])\n            log(\"[bold green]Original images added successfully[/bold green]\")\n\n            xy_data = np.array(xy, dtype=object, copy=False)\n            log(\"[bold green]Augmented data converted to numpy array[/bold green]\")\n            if shuffle:\n                np.random.shuffle(xy_data)\n                log(\"[bold green]Augmented data shuffled successfully[/bold green]\")\n            x_train_data = xy_data[:, 0]\n            log(\"[bold green]x_train_data split successfully[/bold green]\")\n            y_train_data = xy_data[:, 1]\n            log(\"[bold green]y_train_data split successfully[/bold green]\")\n#             x_train_data = x_train_data / 255\n            log(\"[bold green]x_train_data normalized successfully[/bold green]\")\n#             x_test = x_test / 255\n            log(\"[bold green]x_test normalized successfully[/bold green]\")\n\n            if export:\n                if not experimental_export:\n                    x_train_data.dump(os.path.join(export_path, \"x_train.npy\"))\n                    y_train_data.dump(os.path.join(export_path, \"y_train.npy\"))\n                    x_test.dump(os.path.join(export_path, \"x_test.npy\"))\n                    y_test.dump(os.path.join(export_path, \"y_test.npy\"))\n                else:\n                    np.savez_compressed(\n                        os.path.join(export_path, \"data.npz\"),\n                        x_train=x_train_data,\n                        y_train=y_train_data,\n                        x_test=x_test,\n                        y_test=y_test,\n                    )\n                    log(\"[bold green]Dataset exported successfully[/bold green]\")\n\n    else:\n        # x_data = np.array(__x)\n        # x_data.dump(\"Dataset/x.npy\")\n        # Y.dump(\"Dataset/y.npy\")\n#         x_train = x_train / 255\n#         x_test = x_test / 255\n        if export:\n            if not experimental_export:\n                x_train.dump(os.path.join(export_path, \"x_train.npy\"))\n                y_train.dump(os.path.join(export_path, \"y_train.npy\"))\n                x_test.dump(os.path.join(export_path, \"x_test.npy\"))\n                y_test.dump(os.path.join(export_path, \"y_test.npy\"))\n            else:\n                np.savez_compressed(\n                    os.path.join(export_path, \"data.npz\"),\n                    x_train=x_train,\n                    y_train=y_train,\n                    x_test=x_test,\n                    y_test=y_test,\n                )\n\n\nif __name__ == \"__main__\":\n    has_new = False\n    if count_dirs(\"/kaggle/working/new-transfer-data/New-Data/\") > 0:\n        has_new = True\n        export_dataset_objects(\n            path_to_dataset=\"/kaggle/working/new-transfer-data/New-Data/\",\n            shuffle=True,\n            random_state=SHUFFLE_NUMBER,\n            min_faces=0,\n            max_faces=60,\n            hard_limit=False,\n            augment=True,\n            augmentation_upto=120,\n            experimental_export=True,\n            test_size=0.3,\n            desired_shape=(848,464),\n            export=True,\n        )\n","metadata":{"execution":{"iopub.status.busy":"2024-03-20T05:44:00.758824Z","iopub.execute_input":"2024-03-20T05:44:00.759209Z","iopub.status.idle":"2024-03-20T05:46:21.270304Z","shell.execute_reply.started":"2024-03-20T05:44:00.759176Z","shell.execute_reply":"2024-03-20T05:46:21.269122Z"},"trusted":true},"execution_count":null,"outputs":[]},{"cell_type":"code","source":"# load existing dataset\nhas_base = False\nif Path(\"/kaggle/working/transfer-learning-base/Transfer-learning-data-v2/Transfer-learning-data/data.npz\").exists():\n    has_base = True\nif has_base:\n    data = np.load(\"/kaggle/working/transfer-learning-base/Transfer-learning-data-v2/Transfer-learning-data/data.npz\", allow_pickle=True)\n    X = data['x_train']\n    Y = data['y_train']\n    x_test = data['x_test']\n    y_test = data['y_test']\n\n    label_counts = Counter(Y)\n\n    for label, count in label_counts.items():\n        print(f\"Label {label}: {count} images\")\n\n\n    unique_identities = np.unique(Y)\n    n_unique_identities = len(unique_identities)\n\n    print(f\"There are {len(unique_identities)} unique identities.\")","metadata":{"execution":{"iopub.status.busy":"2024-03-20T05:46:21.272695Z","iopub.execute_input":"2024-03-20T05:46:21.273161Z","iopub.status.idle":"2024-03-20T05:46:21.281306Z","shell.execute_reply.started":"2024-03-20T05:46:21.273120Z","shell.execute_reply":"2024-03-20T05:46:21.280163Z"},"trusted":true},"execution_count":null,"outputs":[]},{"cell_type":"code","source":"# load new images into a different variable\nif has_new:\n    new_data = np.load(\"/kaggle/working/new-transfer-data/New-Data/data.npz\", allow_pickle=True)\n    new_X = new_data['x_train']\n    new_Y = new_data['y_train']\n    new_x_test = new_data['x_test']\n    new_y_test = new_data['y_test']\n\n    new_label_counts = Counter(new_Y)\n\n    for label, count in new_label_counts.items():\n        print(f\"Label {label}: {count} images\")\n\n    new_unique_identities = np.unique(new_Y)\n    new_n_unique_identities = len(new_unique_identities)\n\n    print(f\"There are {len(new_unique_identities)} unique identities.\")","metadata":{"execution":{"iopub.status.busy":"2024-03-20T05:46:21.282703Z","iopub.execute_input":"2024-03-20T05:46:21.283027Z","iopub.status.idle":"2024-03-20T05:46:35.081770Z","shell.execute_reply.started":"2024-03-20T05:46:21.283001Z","shell.execute_reply":"2024-03-20T05:46:35.080799Z"},"trusted":true},"execution_count":null,"outputs":[]},{"cell_type":"code","source":"new_X[0].shape","metadata":{"execution":{"iopub.status.busy":"2024-03-20T05:46:35.083945Z","iopub.execute_input":"2024-03-20T05:46:35.084246Z","iopub.status.idle":"2024-03-20T05:46:35.090248Z","shell.execute_reply.started":"2024-03-20T05:46:35.084220Z","shell.execute_reply":"2024-03-20T05:46:35.089283Z"},"trusted":true},"execution_count":null,"outputs":[]},{"cell_type":"code","source":"# augment the new images into a new dataset\n# split the new datasets\n# wait these are already done wtf","metadata":{"execution":{"iopub.status.busy":"2024-03-20T05:46:35.091675Z","iopub.execute_input":"2024-03-20T05:46:35.091924Z","iopub.status.idle":"2024-03-20T05:46:35.100334Z","shell.execute_reply.started":"2024-03-20T05:46:35.091902Z","shell.execute_reply":"2024-03-20T05:46:35.099266Z"},"trusted":true},"execution_count":null,"outputs":[]},{"cell_type":"code","source":"# merge the two datasets in train and test","metadata":{"execution":{"iopub.status.busy":"2024-03-20T05:46:35.101678Z","iopub.execute_input":"2024-03-20T05:46:35.101991Z","iopub.status.idle":"2024-03-20T05:46:35.109946Z","shell.execute_reply.started":"2024-03-20T05:46:35.101966Z","shell.execute_reply":"2024-03-20T05:46:35.108887Z"},"trusted":true},"execution_count":null,"outputs":[]},{"cell_type":"code","source":"# print(X.shape)\n# print(new_X.shape)\nif has_new and has_base:\n    merged_X = np.concatenate((X, new_X))\n#     print(merged_X.shape)\n    merged_Y = np.concatenate((Y, new_Y))\n    merged_x_test = np.concatenate((x_test, new_x_test))\n    merged_y_test = np.concatenate((y_test, new_y_test))\n\n    merged_XY = np.array(list(zip(merged_X, merged_Y)), dtype=object, copy=False)\n    merged_xy_test = np.array(list(zip(merged_x_test, merged_y_test)), dtype=object, copy=False)\n    print(merged_XY.shape)\nelif has_new:\n    merged_X = new_X\n    merged_Y = new_Y\n    merged_x_test = new_x_test\n    merged_y_test = new_y_test\n    merged_XY = np.array(list(zip(merged_X, merged_Y)), dtype=object, copy=False)\n    merged_xy_test = np.array(list(zip(merged_x_test, merged_y_test)), dtype=object, copy=False)\nelif has_base:\n    merged_X = X\n    merged_Y = Y\n    merged_x_test = x_test\n    merged_y_test = y_test\n    merged_XY = np.array(list(zip(merged_X, merged_Y)), dtype=object, copy=False)\n    merged_xy_test = np.array(list(zip(merged_x_test, merged_y_test)), dtype=object, copy=False)\nelse:\n    raise Exception(\"HUH?\")","metadata":{"execution":{"iopub.status.busy":"2024-03-20T05:46:35.111215Z","iopub.execute_input":"2024-03-20T05:46:35.111512Z","iopub.status.idle":"2024-03-20T05:46:35.123607Z","shell.execute_reply.started":"2024-03-20T05:46:35.111478Z","shell.execute_reply":"2024-03-20T05:46:35.122742Z"},"trusted":true},"execution_count":null,"outputs":[]},{"cell_type":"code","source":"np.random.seed(SHUFFLE_NUMBER)\nnp.random.shuffle(merged_XY)\nnp.random.shuffle(merged_xy_test)","metadata":{"execution":{"iopub.status.busy":"2024-03-20T05:46:35.124705Z","iopub.execute_input":"2024-03-20T05:46:35.125003Z","iopub.status.idle":"2024-03-20T05:46:35.139193Z","shell.execute_reply.started":"2024-03-20T05:46:35.124979Z","shell.execute_reply":"2024-03-20T05:46:35.138346Z"},"trusted":true},"execution_count":null,"outputs":[]},{"cell_type":"code","source":"transfer_X = merged_XY[:, 0]\ntransfer_Y = merged_XY[:, 1]\ntransfer_x_test = merged_xy_test[:, 0]\ntransfer_y_test = merged_xy_test[:, 1]","metadata":{"execution":{"iopub.status.busy":"2024-03-20T05:46:35.140267Z","iopub.execute_input":"2024-03-20T05:46:35.140549Z","iopub.status.idle":"2024-03-20T05:46:35.152686Z","shell.execute_reply.started":"2024-03-20T05:46:35.140524Z","shell.execute_reply":"2024-03-20T05:46:35.151951Z"},"trusted":true},"execution_count":null,"outputs":[]},{"cell_type":"code","source":"final_unique_identities = np.unique(transfer_Y)\nfinal_n_unique_identities = len(final_unique_identities)\n\nprint(f\"There are {len(final_unique_identities)} unique identities.\")","metadata":{"execution":{"iopub.status.busy":"2024-03-20T05:46:35.155909Z","iopub.execute_input":"2024-03-20T05:46:35.156255Z","iopub.status.idle":"2024-03-20T05:46:35.171383Z","shell.execute_reply.started":"2024-03-20T05:46:35.156223Z","shell.execute_reply":"2024-03-20T05:46:35.170438Z"},"trusted":true},"execution_count":null,"outputs":[]},{"cell_type":"code","source":"# Function to plot images\ndef plot_images(images, labels, title):\n    fig = plt.figure(figsize=(10,10))\n    fig.suptitle(title)\n    for i in range(5):\n        plt.subplot(1,5,i+1)\n        plt.xticks([])\n        plt.yticks([])\n        plt.grid(False)\n        plt.imshow(images[i], cmap=plt.cm.binary)\n        plt.xlabel(labels[i])\n    plt.tight_layout()\n    plt.show()\n\n# Plot images from X\nplot_images(transfer_X, transfer_Y, \"X\")\n\n# Plot images from x_test\nplot_images(transfer_x_test, transfer_y_test, \"x_test\")","metadata":{"execution":{"iopub.status.busy":"2024-03-20T05:46:35.172434Z","iopub.execute_input":"2024-03-20T05:46:35.172713Z","iopub.status.idle":"2024-03-20T05:46:36.754456Z","shell.execute_reply.started":"2024-03-20T05:46:35.172676Z","shell.execute_reply":"2024-03-20T05:46:36.753436Z"},"trusted":true},"execution_count":null,"outputs":[]},{"cell_type":"code","source":"import cv2\nimport matplotlib.pyplot as plt\n\ndef detect_and_crop_faces_in_image(input_image):\n    face_cascade = cv2.CascadeClassifier(cv2.data.haarcascades + 'haarcascade_frontalface_default.xml')\n\n    image = input_image.copy()\n    \n    faces = face_cascade.detectMultiScale(image, scaleFactor=1.1, minNeighbors=5, minSize=(30, 30))\n    \n    # If a face is detected, crop it out\n    if len(faces) > 0:\n        x, y, w, h = faces[0]\n        cropped_face = image[y:y+h, x:x+w]\n        cropped = True\n    else:\n        cropped = False\n        cropped_face = image\n\n    # Resize the cropped face or the original image to (227, 227)\n    resized_image = cv2.resize(cropped_face, (224, 224))\n    return resized_image, cropped\n\ncropped_face_X = []\ncropped_face_x_test = []\ncropped_face_Y = []\ncropped_face_y_test = []\n\ntracker = tqdm.tqdm\n\nfor image, label in tracker(list(zip(transfer_X, transfer_Y))):\n    cropped_face, cropped = detect_and_crop_faces_in_image(image)\n    if cropped:\n        cropped_face_X.append(cropped_face) \n        cropped_face_Y.append(label)\n\nfor image, label in tracker(list(zip(transfer_x_test, transfer_y_test))):\n    cropped_face, cropped = detect_and_crop_faces_in_image(image)\n    if cropped:\n        cropped_face_x_test.append(cropped_face)\n        cropped_face_y_test.append(label)","metadata":{"execution":{"iopub.status.busy":"2024-03-20T05:47:20.579726Z","iopub.execute_input":"2024-03-20T05:47:20.580124Z","iopub.status.idle":"2024-03-20T05:51:16.757930Z","shell.execute_reply.started":"2024-03-20T05:47:20.580092Z","shell.execute_reply":"2024-03-20T05:51:16.756972Z"},"trusted":true},"execution_count":null,"outputs":[]},{"cell_type":"code","source":"fig, axes = plt.subplots(2, 5, figsize=(40, 10))\naxes = axes.flatten()\nfor i in range(10):\n    if i < 5:\n        ax = axes[i]\n        ax.imshow(cropped_face_X[i], cmap=\"gray\")\n        ax.axis(\"off\")\n    else:\n        ax = axes[i]\n        ax.imshow(cropped_face_x_test[i - 5])\n        ax.axis(\"off\")\nplt.tight_layout()\nplt.show()","metadata":{"execution":{"iopub.status.busy":"2024-03-20T05:51:49.337127Z","iopub.execute_input":"2024-03-20T05:51:49.337511Z","iopub.status.idle":"2024-03-20T05:51:50.981405Z","shell.execute_reply.started":"2024-03-20T05:51:49.337480Z","shell.execute_reply":"2024-03-20T05:51:50.978178Z"},"trusted":true},"execution_count":null,"outputs":[]},{"cell_type":"code","source":"if tf.test.gpu_device_name():\n    print('Default GPU Device: {}'.format(tf.test.gpu_device_name()))\nelse:\n    print(\"Please install GPU version of TF\")\n\n# def normalize_images(image_array):\n#     # Normalize the images \n#     for i, image in enumerate(image_array):\n#         image = ((image - np.min(image)) / (np.max(image) - np.min(image)))\n#         image_array[i] = image\n#     return image_array\n\ndef normalize_image(image):\n    final = ((image - tf.math.reduce_min(image)) / (tf.math.reduce_max(image) - tf.math.reduce_min(image)))\n    if tf.reduce_any(tf.math.is_nan(final)):\n        print(\"NAN FOUND\")\n        final = ((image - tf.math.reduce_min(image)) / 1)\n    return final\n\n# # Apply the function to our final_X and final_x_test \n# final_X = normalize_images(cropped_face_X)\n# final_x_test = normalize_images(cropped_face_x_test)\n\n# Convert lists to Numpy arrays\n# final_X = np.array(final_X)\n# final_x_test = np.array(final_x_test)\n\n\n# X_data = tf.data.Dataset.from_generator(iter(cropped_face_X))\n# x_test_data = tf.data.Dataset.from_generator(iter(cropped_face_x_test))\n\n# final_X = X_data.apply(normalize_image)\n# final_x_test = x_test_data.apply(normalize_image)\n\n# Initialize the label encoder\nle = LabelEncoder()\n\n# Fit the label encoder and transform the labels\nY_int = le.fit_transform(cropped_face_Y)\nprint(Y_int)\n\nY_one_hot = to_categorical(Y_int, num_classes=final_n_unique_identities)\n\ndataset_size = int(len(cropped_face_X))\n\ntrain_val_data = tf.data.Dataset.from_tensor_slices((cropped_face_X, Y_one_hot))\nprint(\"created tensor slice\")\ntrain_val_data = train_val_data.map(lambda x, y: (normalize_image(x), y))\nprint(\"added mapping\")\n\ntrain_val_data = train_val_data.shuffle(5000)\nprint(\"shuffled\")\ntrain_data = train_val_data.take(int(0.9 * dataset_size)).batch(32)\nprint(\"train data\")\nval_data = train_val_data.skip(int(0.9 * dataset_size)).batch(32)\nprint(\"val data\")","metadata":{"execution":{"iopub.status.busy":"2024-03-20T05:52:58.436047Z","iopub.execute_input":"2024-03-20T05:52:58.436450Z","iopub.status.idle":"2024-03-20T05:56:36.016055Z","shell.execute_reply.started":"2024-03-20T05:52:58.436416Z","shell.execute_reply":"2024-03-20T05:56:36.015084Z"},"trusted":true},"execution_count":null,"outputs":[]},{"cell_type":"code","source":"%pip show keras","metadata":{"execution":{"iopub.status.busy":"2024-03-20T05:56:36.018109Z","iopub.execute_input":"2024-03-20T05:56:36.018415Z","iopub.status.idle":"2024-03-20T05:56:48.857662Z","shell.execute_reply.started":"2024-03-20T05:56:36.018388Z","shell.execute_reply":"2024-03-20T05:56:48.855958Z"},"trusted":true},"execution_count":null,"outputs":[]},{"cell_type":"code","source":"# load model\nmodel = keras.models.load_model('/kaggle/working/transfer-learning-base/Transfer-learning-data-v2/Transfer-learning-data/model_mobilenet-base.h5')","metadata":{"execution":{"iopub.status.busy":"2024-03-20T05:56:48.859801Z","iopub.execute_input":"2024-03-20T05:56:48.860317Z","iopub.status.idle":"2024-03-20T05:56:50.136287Z","shell.execute_reply.started":"2024-03-20T05:56:48.860265Z","shell.execute_reply":"2024-03-20T05:56:50.135313Z"},"trusted":true},"execution_count":null,"outputs":[]},{"cell_type":"code","source":"# %pip install keras==2.15.0","metadata":{"execution":{"iopub.status.busy":"2024-03-20T05:56:50.139487Z","iopub.execute_input":"2024-03-20T05:56:50.140239Z","iopub.status.idle":"2024-03-20T05:56:50.144710Z","shell.execute_reply.started":"2024-03-20T05:56:50.140200Z","shell.execute_reply":"2024-03-20T05:56:50.143637Z"},"trusted":true},"execution_count":null,"outputs":[]},{"cell_type":"code","source":"# %pip show tensorflow\n# %pip show keras","metadata":{"execution":{"iopub.status.busy":"2024-03-20T05:56:50.146100Z","iopub.execute_input":"2024-03-20T05:56:50.146468Z","iopub.status.idle":"2024-03-20T05:56:50.155972Z","shell.execute_reply.started":"2024-03-20T05:56:50.146433Z","shell.execute_reply":"2024-03-20T05:56:50.154945Z"},"trusted":true},"execution_count":null,"outputs":[]},{"cell_type":"code","source":"# model.summary()","metadata":{"execution":{"iopub.status.busy":"2024-03-20T05:56:50.157147Z","iopub.execute_input":"2024-03-20T05:56:50.157459Z","iopub.status.idle":"2024-03-20T05:56:50.166293Z","shell.execute_reply.started":"2024-03-20T05:56:50.157433Z","shell.execute_reply":"2024-03-20T05:56:50.165338Z"},"trusted":true},"execution_count":null,"outputs":[]},{"cell_type":"code","source":"# destroy top\n","metadata":{"execution":{"iopub.status.busy":"2024-03-20T05:56:50.167349Z","iopub.execute_input":"2024-03-20T05:56:50.167642Z","iopub.status.idle":"2024-03-20T05:56:50.175396Z","shell.execute_reply.started":"2024-03-20T05:56:50.167617Z","shell.execute_reply":"2024-03-20T05:56:50.174388Z"},"trusted":true},"execution_count":null,"outputs":[]},{"cell_type":"code","source":"model.trainable = False","metadata":{"execution":{"iopub.status.busy":"2024-03-20T05:56:50.176471Z","iopub.execute_input":"2024-03-20T05:56:50.176857Z","iopub.status.idle":"2024-03-20T05:56:50.189075Z","shell.execute_reply.started":"2024-03-20T05:56:50.176809Z","shell.execute_reply":"2024-03-20T05:56:50.188171Z"},"trusted":true},"execution_count":null,"outputs":[]},{"cell_type":"code","source":"# create new top\nnew_layer = keras.layers.Dense(final_n_unique_identities, activation='softmax', name=\"dense_output\")(model.layers[-2].output)","metadata":{"execution":{"iopub.status.busy":"2024-03-20T05:56:50.190167Z","iopub.execute_input":"2024-03-20T05:56:50.190482Z","iopub.status.idle":"2024-03-20T05:56:50.215300Z","shell.execute_reply.started":"2024-03-20T05:56:50.190448Z","shell.execute_reply":"2024-03-20T05:56:50.214441Z"},"trusted":true},"execution_count":null,"outputs":[]},{"cell_type":"code","source":"transfer_model = keras.models.Model(inputs=model.input, outputs=new_layer)","metadata":{"execution":{"iopub.status.busy":"2024-03-20T05:56:50.218506Z","iopub.execute_input":"2024-03-20T05:56:50.218813Z","iopub.status.idle":"2024-03-20T05:56:50.233965Z","shell.execute_reply.started":"2024-03-20T05:56:50.218779Z","shell.execute_reply":"2024-03-20T05:56:50.232943Z"},"trusted":true},"execution_count":null,"outputs":[]},{"cell_type":"code","source":"transfer_model.summary()","metadata":{"execution":{"iopub.status.busy":"2024-03-20T05:56:50.235341Z","iopub.execute_input":"2024-03-20T05:56:50.236121Z","iopub.status.idle":"2024-03-20T05:56:50.453305Z","shell.execute_reply.started":"2024-03-20T05:56:50.236084Z","shell.execute_reply":"2024-03-20T05:56:50.452319Z"},"trusted":true},"execution_count":null,"outputs":[]},{"cell_type":"code","source":"base_learning_rate = 0.00005\ntransfer_model.compile(optimizer=keras.optimizers.Adam(learning_rate=base_learning_rate),\n                       loss=tf.keras.losses.CategoricalCrossentropy(from_logits=True),\n                       metrics=[\"accuracy\"])","metadata":{"execution":{"iopub.status.busy":"2024-03-20T05:56:50.454560Z","iopub.execute_input":"2024-03-20T05:56:50.454912Z","iopub.status.idle":"2024-03-20T05:56:50.501062Z","shell.execute_reply.started":"2024-03-20T05:56:50.454884Z","shell.execute_reply":"2024-03-20T05:56:50.500053Z"},"trusted":true},"execution_count":null,"outputs":[]},{"cell_type":"code","source":"# base_learning_rate = 0.001\n# model.compile(optimizer=keras.optimizers.Adam(learning_rate=base_learning_rate),\n#                        loss=keras.losses.CategoricalCrossentropy(from_logits=False),\n#                        metrics=[\"accuracy\"])","metadata":{"execution":{"iopub.status.busy":"2024-03-20T05:56:50.502247Z","iopub.execute_input":"2024-03-20T05:56:50.502560Z","iopub.status.idle":"2024-03-20T05:56:50.508633Z","shell.execute_reply.started":"2024-03-20T05:56:50.502535Z","shell.execute_reply":"2024-03-20T05:56:50.507620Z"},"trusted":true},"execution_count":null,"outputs":[]},{"cell_type":"code","source":"","metadata":{},"execution_count":null,"outputs":[]},{"cell_type":"code","source":"# train\ntransfer_model.fit(train_data, epochs=50, validation_data=val_data, callbacks=keras.callbacks.EarlyStopping(patience=5))","metadata":{"execution":{"iopub.status.busy":"2024-03-20T05:56:50.510332Z","iopub.execute_input":"2024-03-20T05:56:50.510756Z","iopub.status.idle":"2024-03-20T05:59:33.403549Z","shell.execute_reply.started":"2024-03-20T05:56:50.510719Z","shell.execute_reply":"2024-03-20T05:59:33.402411Z"},"trusted":true},"execution_count":null,"outputs":[]},{"cell_type":"code","source":"# Initialize the label encoder\n# le = LabelEncoder()\n\n# Fit the label encoder and transform the labels\n# Y_int_test = le.fit_transform(y_test)\n# Y_int_test = le.inverse_transform(y_test)\nY_int_test = le.transform(cropped_face_y_test)\nY_one_hot_test = to_categorical(Y_int_test, num_classes=final_n_unique_identities)","metadata":{"execution":{"iopub.status.busy":"2024-03-20T05:59:33.410100Z","iopub.execute_input":"2024-03-20T05:59:33.410446Z","iopub.status.idle":"2024-03-20T05:59:33.416127Z","shell.execute_reply.started":"2024-03-20T05:59:33.410418Z","shell.execute_reply":"2024-03-20T05:59:33.415200Z"},"trusted":true},"execution_count":null,"outputs":[]},{"cell_type":"code","source":"from sklearn.metrics import classification_report\n\ntest_data = tf.data.Dataset.from_tensor_slices((cropped_face_x_test,))\ntest_data = test_data.map(lambda x: (normalize_image(x))).batch(32)\n\n# models = {}\n# for model_file in os.listdir(\"/kaggle/input/test-models/model\"):\n#     if model_file.endswith(\".h5\"):\n#         models[model_file] = load_model(\"/kaggle/input/test-models/model/\" + model_file)\n\n# for model in models:\n\nprint(f\"Model: {transfer_model}\")\nval_predictions = transfer_model.predict(test_data)\n\n# Convert predictions classes to one hot vectors \nval_predictions_classes = np.argmax(val_predictions, axis = 1) \n# Convert validation observations to one hot vectors\nval_true = np.argmax(Y_one_hot_test, axis = 1)\n\n# Generate the classification report\nreport = classification_report(val_true, val_predictions_classes)\nprint(report)\n","metadata":{"execution":{"iopub.status.busy":"2024-03-20T05:59:33.417269Z","iopub.execute_input":"2024-03-20T05:59:33.417530Z","iopub.status.idle":"2024-03-20T05:59:47.529029Z","shell.execute_reply.started":"2024-03-20T05:59:33.417507Z","shell.execute_reply":"2024-03-20T05:59:47.527983Z"},"trusted":true},"execution_count":null,"outputs":[]},{"cell_type":"code","source":"!mkdir -p /kaggle/working/export","metadata":{"execution":{"iopub.status.busy":"2024-03-20T05:59:47.530438Z","iopub.execute_input":"2024-03-20T05:59:47.530819Z","iopub.status.idle":"2024-03-20T05:59:48.950944Z","shell.execute_reply.started":"2024-03-20T05:59:47.530790Z","shell.execute_reply":"2024-03-20T05:59:48.949334Z"},"trusted":true},"execution_count":null,"outputs":[]},{"cell_type":"code","source":"with open(Path(\"/kaggle/working/export/labels.txt\"), \"w\") as f:\n    for c in le.classes_:\n        f.write(f\"{c}\\n\")","metadata":{"execution":{"iopub.status.busy":"2024-03-20T05:59:48.952753Z","iopub.execute_input":"2024-03-20T05:59:48.953112Z","iopub.status.idle":"2024-03-20T05:59:48.959934Z","shell.execute_reply.started":"2024-03-20T05:59:48.953078Z","shell.execute_reply":"2024-03-20T05:59:48.958724Z"},"trusted":true},"execution_count":null,"outputs":[]},{"cell_type":"code","source":"# export model and dataset\nexport_time = math.floor(time.time())\ntransfer_model.save(f'/kaggle/working/export/transfer-model-mobilenet-25I-{export_time}.h5')","metadata":{"execution":{"iopub.status.busy":"2024-03-20T05:59:48.961595Z","iopub.execute_input":"2024-03-20T05:59:48.961996Z","iopub.status.idle":"2024-03-20T05:59:49.198612Z","shell.execute_reply.started":"2024-03-20T05:59:48.961959Z","shell.execute_reply":"2024-03-20T05:59:49.197649Z"},"trusted":true},"execution_count":null,"outputs":[]},{"cell_type":"code","source":"np.savez_compressed(\n    \"/kaggle/working/export/data.npz\",\n    x_train=transfer_X,\n    y_train=transfer_Y,\n    x_test=transfer_x_test,\n    y_test=transfer_y_test\n)","metadata":{"execution":{"iopub.status.busy":"2024-03-20T05:59:49.203721Z","iopub.execute_input":"2024-03-20T05:59:49.204072Z","iopub.status.idle":"2024-03-20T06:00:54.596738Z","shell.execute_reply.started":"2024-03-20T05:59:49.204043Z","shell.execute_reply":"2024-03-20T06:00:54.595786Z"},"trusted":true},"execution_count":null,"outputs":[]},{"cell_type":"code","source":"!rm -rf /kaggle/working/transfer-learning-base\n!rm -rf /kaggle/working/mates-only-v3\n!rm -rf /kaggle/working/new-transfer-data","metadata":{"execution":{"iopub.status.busy":"2024-03-20T06:00:54.597858Z","iopub.execute_input":"2024-03-20T06:00:54.598127Z","iopub.status.idle":"2024-03-20T06:00:58.864062Z","shell.execute_reply.started":"2024-03-20T06:00:54.598104Z","shell.execute_reply":"2024-03-20T06:00:58.862775Z"},"trusted":true},"execution_count":null,"outputs":[]},{"cell_type":"code","source":"shutil.make_archive('/kaggle/working/export_data', 'zip', '/kaggle/working/export')","metadata":{"execution":{"iopub.status.busy":"2024-03-20T06:00:58.865903Z","iopub.execute_input":"2024-03-20T06:00:58.866263Z","iopub.status.idle":"2024-03-20T06:01:29.442194Z","shell.execute_reply.started":"2024-03-20T06:00:58.866230Z","shell.execute_reply":"2024-03-20T06:01:29.441191Z"},"trusted":true},"execution_count":null,"outputs":[]},{"cell_type":"code","source":"!rm -rf /kaggle/working/export","metadata":{"execution":{"iopub.status.busy":"2024-03-20T06:01:29.444105Z","iopub.execute_input":"2024-03-20T06:01:29.444559Z","iopub.status.idle":"2024-03-20T06:01:30.947442Z","shell.execute_reply.started":"2024-03-20T06:01:29.444522Z","shell.execute_reply":"2024-03-20T06:01:30.946016Z"},"trusted":true},"execution_count":null,"outputs":[]}]}